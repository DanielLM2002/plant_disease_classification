{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esteban Castañeda Blanco C01795\n",
    "\n",
    "Israel López Vallecillo C04396\n",
    "\n",
    "Daniel Lizano Morales C04285\n",
    "\n",
    "Ariel Solís Monge B97664"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "import wandb\n",
    "import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\esteb\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=config.API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.USE_UNET: import unet as autoencoder\n",
    "else: import convolutional_autoencoder as autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_train_relative_set_size = round((config.LABELED_TRAIN_SET_ABSOLUTE_SIZE / (1 - config.UNLABELED_SET_SIZE)), 2)\n",
    "labeled_test_relative_set_size = 1 - labeled_train_relative_set_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set up of the device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")#tqm\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'bce': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'mse': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4641, 0.4891, 0.4096], [0.1883, 0.1621, 0.2068])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = datasets.ImageFolder(config.BASE_DIR_RAW, transform=data_transforms[config.AE_TRANSFORMS])\n",
    "full_noisy_dataset = datasets.ImageFolder(config.BASE_DIR_NOISY, transform=data_transforms[config.AE_TRANSFORMS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(full_dataset)))\n",
    "noisy_indices =list(range(len(full_noisy_dataset)))\n",
    "\n",
    "# Get the directory paths of images\n",
    "image_paths = [sample[0] for sample in full_dataset.samples]\n",
    "noisy_image_paths = [sample[0] for sample in full_noisy_dataset.samples]\n",
    "\n",
    "labels = [os.path.split(os.path.dirname(path))[-1] for path in image_paths]\n",
    "noisy_labels = [os.path.split(os.path.dirname(path))[-1] for path in noisy_image_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos el 20% de los datos \n",
    "train_val_indices, _  = train_test_split(indices, test_size=config.UNLABELED_SET_SIZE, stratify=labels, random_state=42)#Obtenemos el 20% de los datos \n",
    "noisy_train_val_indices, _ = train_test_split(noisy_indices, test_size=config.UNLABELED_SET_SIZE, stratify=noisy_labels, random_state=42)\n",
    "\n",
    "#Obtenemos las etiquetas de los datos de entrenamiento\n",
    "train_val_labels = [labels[i] for i in train_val_indices]\n",
    "noisy_train_val_labels = [noisy_labels[i] for i in noisy_train_val_indices]\n",
    "\n",
    "#dividir el 20% en 10% de entrenamiento y 10% de validación\n",
    "train_indices, val_indices = train_test_split(train_val_indices, test_size=labeled_test_relative_set_size, stratify=train_val_labels, random_state=42)\n",
    "noisy_train_indices, noisy_val_indices = train_test_split(noisy_train_val_indices, test_size=labeled_test_relative_set_size, stratify=noisy_train_val_labels, random_state=42)\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "noisy_train_dataset = Subset(full_noisy_dataset, noisy_train_indices)\n",
    "val_dataset = Subset(full_dataset, val_indices)\n",
    "noisy_val_dataset = Subset(full_dataset, noisy_val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imágenes en el conjunto de entrenamiento: 6148\n",
      "Número de imágenes en el conjunto de entrenamiento: 6148\n",
      "Número de imágenes en el conjunto de validación: 6149\n",
      "Número de imágenes en el conjunto de validación: 6149\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "noisy_loader = DataLoader(noisy_train_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=4)\n",
    "noisy_val_loader = DataLoader(noisy_val_dataset, batch_size=4, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Número de imágenes en el conjunto de entrenamiento: {len(train_loader.dataset)}\")\n",
    "print(f\"Número de imágenes en el conjunto de entrenamiento: {len(noisy_loader.dataset)}\")\n",
    "print(f\"Número de imágenes en el conjunto de validación: {len(val_loader.dataset)}\")\n",
    "print(f\"Número de imágenes en el conjunto de validación: {len(noisy_val_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(cm, annot=True, cmap=plt.cm.Blues, fmt='g', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, device, num_epochs=10, patience=3):\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    wandb_name = config.CNN_DENOISING_SAVE_PATH if config.USE_DENOISING_AUTOENCODER else config.CNN_ENCODER_SAVE_PATH\n",
    "\n",
    "    wandb.init(project=\"cnn_encoder_training\", name=wandb_name)    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = correct / total\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Train Loss: {train_loss:.4f} Acc: {train_acc:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc\n",
    "        })\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), config.CNN_ENCODER_SAVE_PATH)\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_path, dataloader, device):\n",
    "    model = models.efficientnet_b2(pretrained=False)\n",
    "    new_in_channels = 1\n",
    "    original_conv1 = model.features[0][0]\n",
    "    wandb_name = config.CNN_DENOISING_SAVE_PATH if config.USE_DENOISING_AUTOENCODER else config.CNN_ENCODER_SAVE_PATH\n",
    "\n",
    "    wandb.init(project=\"cnn_encoder_evaluation\", name=wandb_name)\n",
    "\n",
    "    new_conv1 = nn.Conv2d(\n",
    "        in_channels=new_in_channels,\n",
    "        out_channels=original_conv1.out_channels,\n",
    "        kernel_size=original_conv1.kernel_size,\n",
    "        stride=original_conv1.stride,\n",
    "        padding=original_conv1.padding,\n",
    "        bias=original_conv1.bias\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        if new_in_channels == 1:\n",
    "            new_conv1.weight = nn.Parameter(original_conv1.weight.mean(dim=1, keepdim=True))\n",
    "        else:\n",
    "            new_conv1.weight[:, :3] = original_conv1.weight\n",
    "            if new_in_channels > 3:\n",
    "                for i in range(3, new_in_channels):\n",
    "                    new_conv1.weight[:, i:i+1] = original_conv1.weight.mean(dim=1, keepdim=True)\n",
    "    model.features[0][0] = new_conv1\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plot_confusion_matrix(cm, class_names=dataloader.dataset.dataset.classes)\n",
    "    class_names = dataloader.dataset.dataset.classes\n",
    "    precision = precision_score(all_labels, all_preds, average=None)\n",
    "    recall = recall_score(all_labels, all_preds, average=None)\n",
    "    class_accuracies = cm.diagonal() / cm.sum(axis=1)\n",
    "    \n",
    "    print(f'Overall Accuracy: {accuracy:.4f}')\n",
    "    print(\"\\nMetrics by Class:\")\n",
    "    print(\"{:<20} {:<10} {:<10} {:<10}\".format(\"Class\", \"Accuracy\", \"Precision\", \"Recall\"))\n",
    "    print(\"=\"*50)\n",
    "    for class_name, class_accuracy, class_precision, class_recall in zip(class_names, class_accuracies, precision, recall):\n",
    "        print(\"{:<20} {:<10.4f} {:<10.4f} {:<10.4f}\".format(class_name, class_accuracy, class_precision, class_recall))\n",
    "\n",
    "    wandb.log({\n",
    "        \"overall_accuracy\": accuracy,\n",
    "        \"confusion_matrix\": wandb.plot.confusion_matrix(probs=None, y_true=all_labels, preds=all_preds, class_names=class_names),\n",
    "        \"precision\": {class_name: class_precision for class_name, class_precision in zip(class_names, precision)},\n",
    "        \"recall\": {class_name: class_recall for class_name, class_recall in zip(class_names, recall)},\n",
    "        \"class_accuracies\": {class_name: class_accuracy for class_name, class_accuracy in zip(class_names, class_accuracies)}\n",
    "    })\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the encoder model\n",
    "def load_encoder(model_path, device):\n",
    "    model = autoencoder.AutoEncoder()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    encoder = model.encoder\n",
    "    encoder = encoder.to(device)\n",
    "    return model, encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder + CNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified first conv layer: Conv2d(2, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    }
   ],
   "source": [
    "cnn_model = models.efficientnet_b2()\n",
    "\n",
    "# Modify the first convolutional layer to accept a different number of input channels (e.g., 1 instead of 3)\n",
    "new_in_channels = config.LATENT_CHANNELS  # Change this to the desired number of input channels\n",
    "original_conv1 = cnn_model.features[0][0]\n",
    "\n",
    "new_conv1 = nn.Conv2d(\n",
    "    in_channels=new_in_channels,\n",
    "    out_channels=original_conv1.out_channels,\n",
    "    kernel_size=original_conv1.kernel_size,\n",
    "    stride=original_conv1.stride,\n",
    "    padding=original_conv1.padding,\n",
    "    bias=original_conv1.bias\n",
    ")\n",
    "\n",
    "# Inicializar los pesos de la nueva capa convolucional\n",
    "with torch.no_grad():\n",
    "    if new_in_channels == 1:\n",
    "        # Promediar los pesos de la capa original a través de los canales de entrada\n",
    "        new_conv1.weight = nn.Parameter(original_conv1.weight.mean(dim=1, keepdim=True))\n",
    "    else:\n",
    "        # Inicializar pesos promediando los pesos de los primeros dos canales\n",
    "        new_conv1.weight[:, :2] = original_conv1.weight[:, :2].mean(dim=1, keepdim=True)\n",
    "        if new_in_channels > 2:\n",
    "            for i in range(2, new_in_channels):\n",
    "                new_conv1.weight[:, i:i+1] = original_conv1.weight.mean(dim=1, keepdim=True)\n",
    "\n",
    "# Reemplazar la primera capa convolucional en el modelo\n",
    "cnn_model.features[0][0] = new_conv1\n",
    "# model._conv_stem = nn.Conv2d(1, model._conv_stem.out_channels, kernel_size=model._conv_stem.kernel_size, stride=model._conv_stem.stride, padding=model._conv_stem.padding, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, encoder_model, cnn_model):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        self.encoder = encoder_model\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(config.LATENT_DIM, config.LATENT_CHANNELS * 288 * 288)\n",
    "\t\t)\n",
    "        self.cnn = cnn_model\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        if config.USE_UNET: x = x[4]\n",
    "        # print(x.shape)\n",
    "        x = self.fc(x)\n",
    "        x = x.reshape(x.shape[0], config.LATENT_CHANNELS, 288, 288)\n",
    "        output = self.cnn(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder, encoder_model = load_encoder(config.AUTOENCODER_SAVE_PATH, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (inc): InConv(\n",
       "    (conv): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (mpconv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (mpconv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (mpconv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): Down(\n",
       "    (mpconv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EncoderCNN(encoder_model, cnn_model)\n",
    "model = model.to(device)\n",
    "model.encoder.requires_grad_(config.TRAIN_ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\esteb\\Documents\\plant_disease_classification\\wandb\\run-20240701_181251-lbm43y8d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ci-0148-g3/cnn_encoder_training/runs/lbm43y8d' target=\"_blank\">best_models\\h1_80-10-10_classifierB.pth</a></strong> to <a href='https://wandb.ai/ci-0148-g3/cnn_encoder_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ci-0148-g3/cnn_encoder_training' target=\"_blank\">https://wandb.ai/ci-0148-g3/cnn_encoder_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ci-0148-g3/cnn_encoder_training/runs/lbm43y8d' target=\"_blank\">https://wandb.ai/ci-0148-g3/cnn_encoder_training/runs/lbm43y8d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1537 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1537 [00:16<6:50:09, 16.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1537 [00:17<3:11:21,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1537 [00:19<2:02:09,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1537 [00:20<1:29:17,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1537 [00:22<1:10:58,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/1537 [00:23<59:48,  2.34s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/1537 [00:25<53:14,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1537 [00:26<48:22,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1537 [00:28<44:54,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1537 [00:29<44:02,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1537 [00:31<42:24,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1537 [00:32<41:01,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/1537 [00:34<40:33,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/1537 [00:35<40:28,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/1537 [00:37<39:43,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/1537 [00:38<39:14,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/1537 [00:40<40:18,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/1537 [00:42<40:01,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/1537 [00:43<39:22,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 20/1537 [00:45<39:44,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 21/1537 [00:46<40:03,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 22/1537 [00:48<39:44,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 23/1537 [00:50<39:59,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 24/1537 [00:51<40:44,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 25/1537 [00:53<40:02,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 26/1537 [00:54<39:38,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 27/1537 [00:56<39:07,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 28/1537 [00:57<39:22,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 29/1537 [00:59<39:03,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 30/1537 [01:01<39:31,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 31/1537 [01:02<40:42,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 32/1537 [01:04<40:41,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 33/1537 [01:06<40:06,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 34/1537 [01:07<41:16,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 35/1537 [01:09<40:15,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 36/1537 [01:10<40:19,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 37/1537 [01:12<40:35,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 38/1537 [01:14<41:08,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 39/1537 [01:15<40:13,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 40/1537 [01:17<39:36,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 41/1537 [01:19<40:57,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 42/1537 [01:20<40:18,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 43/1537 [01:22<39:35,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 44/1537 [01:23<40:21,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 45/1537 [01:25<40:44,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 46/1537 [01:27<41:04,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 47/1537 [01:30<47:33,  1.92s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mUSE_DENOISING_AUTOENCODER:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPATIENCE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m     train_model(model, criterion, optimizer, noisy_loader, noisy_val_loader, device, num_epochs\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mEPOCHS, patience\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mPATIENCE)\n",
      "Cell \u001b[1;32mIn[87], line 17\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, train_loader, val_loader, device, num_epochs, patience)\u001b[0m\n\u001b[0;32m     15\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[91], line 9\u001b[0m, in \u001b[0;36mEncoderCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m----> 9\u001b[0m     _, _, _, _, x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], config\u001b[38;5;241m.\u001b[39mLATENT_CHANNELS, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\unet.py:96\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     94\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minc(x)\n\u001b[0;32m     95\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown1(x1)\n\u001b[1;32m---> 96\u001b[0m x3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m x4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown3(x3)\n\u001b[0;32m     98\u001b[0m x5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown4(x4)\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\unet.py:43\u001b[0m, in \u001b[0;36mDown.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 43\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmpconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\unet.py:20\u001b[0m, in \u001b[0;36mDoubleConv.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 20\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\esteb\\Documents\\plant_disease_classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not config.USE_DENOISING_AUTOENCODER:\n",
    "    train_model(model, criterion, optimizer, train_loader, val_loader, device, num_epochs=config.EPOCHS, patience=config.PATIENCE)\n",
    "else:\n",
    "    train_model(model, criterion, optimizer, noisy_loader, noisy_val_loader, device, num_epochs=config.EPOCHS, patience=config.PATIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(cm, annot=True, cmap=plt.cm.Blues, fmt='g', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dylan\\Desktop\\plant_disease_classification\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dylan\\Desktop\\plant_disease_classification\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:0kcube8b) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>train_acc</td><td>▁▅▅▅▆▆▇█▅▆█▇</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▂▁▁▁</td></tr><tr><td>val_acc</td><td>▂▅▁▄█▃▃▃▄▄▃▅</td></tr><tr><td>val_loss</td><td>▆█▁▁▁▁▁▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>12</td></tr><tr><td>train_acc</td><td>0.09532</td></tr><tr><td>train_loss</td><td>3.54077</td></tr><tr><td>val_acc</td><td>0.09806</td></tr><tr><td>val_loss</td><td>3.51119</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">best_models\\h1_80-10-10_classifierB.pth</strong> at: <a href='https://wandb.ai/ci-0148-g3/cnn_encoder_training/runs/0kcube8b' target=\"_blank\">https://wandb.ai/ci-0148-g3/cnn_encoder_training/runs/0kcube8b</a><br/> View project at: <a href='https://wandb.ai/ci-0148-g3/cnn_encoder_training' target=\"_blank\">https://wandb.ai/ci-0148-g3/cnn_encoder_training</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240627_111022-0kcube8b\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:0kcube8b). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\dylan\\Desktop\\plant_disease_classification\\wandb\\run-20240627_112916-2cmlv504</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ci-0148-g3/cnn_encoder_evaluation/runs/2cmlv504' target=\"_blank\">best_models\\h1_80-10-10_classifierB.pth</a></strong> to <a href='https://wandb.ai/ci-0148-g3/cnn_encoder_evaluation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ci-0148-g3/cnn_encoder_evaluation' target=\"_blank\">https://wandb.ai/ci-0148-g3/cnn_encoder_evaluation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ci-0148-g3/cnn_encoder_evaluation/runs/2cmlv504' target=\"_blank\">https://wandb.ai/ci-0148-g3/cnn_encoder_evaluation/runs/2cmlv504</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for EfficientNet:\n\tMissing key(s) in state_dict: \"features.0.0.weight\", \"features.0.1.weight\", \"features.0.1.bias\", \"features.0.1.running_mean\", \"features.0.1.running_var\", \"features.1.0.block.0.0.weight\", \"features.1.0.block.0.1.weight\", \"features.1.0.block.0.1.bias\", \"features.1.0.block.0.1.running_mean\", \"features.1.0.block.0.1.running_var\", \"features.1.0.block.1.fc1.weight\", \"features.1.0.block.1.fc1.bias\", \"features.1.0.block.1.fc2.weight\", \"features.1.0.block.1.fc2.bias\", \"features.1.0.block.2.0.weight\", \"features.1.0.block.2.1.weight\", \"features.1.0.block.2.1.bias\", \"features.1.0.block.2.1.running_mean\", \"features.1.0.block.2.1.running_var\", \"features.1.1.block.0.0.weight\", \"features.1.1.block.0.1.weight\", \"features.1.1.block.0.1.bias\", \"features.1.1.block.0.1.running_mean\", \"features.1.1.block.0.1.running_var\", \"features.1.1.block.1.fc1.weight\", \"features.1.1.block.1.fc1.bias\", \"features.1.1.block.1.fc2.weight\", \"features.1.1.block.1.fc2.bias\", \"features.1.1.block.2.0.weight\", \"features.1.1.block.2.1.weight\", \"features.1.1.block.2.1.bias\", \"features.1.1.block.2.1.running_mean\", \"features.1.1.block.2.1.running_var\", \"features.2.0.block.0.0.weight\", \"features.2.0.block.0.1.weight\", \"features.2.0.block.0.1.bias\", \"features.2.0.block.0.1.running_mean\", \"features.2.0.block.0.1.running_var\", \"features.2.0.block.1.0.weight\", \"features.2.0.block.1.1.weight\", \"features.2.0.block.1.1.bias\", \"features.2.0.block.1.1.running_mean\", \"features.2.0.block.1.1.running_var\", \"features.2.0.block.2.fc1.weight\", \"features.2.0.block.2.fc1.bias\", \"features.2.0.block.2.fc2.weight\", \"features.2.0.block.2.fc2.bias\", \"features.2.0.block.3.0.weight\", \"features.2.0.block.3.1.weight\", \"features.2.0.block.3.1.bias\", \"features.2.0.block.3.1.running_mean\", \"features.2.0.block.3.1.running_var\", \"features.2.1.block.0.0.weight\", \"features.2.1.block.0.1.weight\", \"features.2.1.block.0.1.bias\", \"features.2.1.block.0.1.running_mean\", \"features.2.1.block.0.1.running_var\", \"features.2.1.block.1.0.weight\", \"features.2.1.block.1.1.weight\", \"features.2.1.block.1.1.bias\", \"features.2.1.block.1.1.running_mean\", \"features.2.1.block.1.1.running_var\", \"features.2.1.block.2.fc1.weight\", \"features.2.1.block.2.fc1.bias\", \"features.2.1.block.2.fc2.weight\", \"features.2.1.block.2.fc2.bias\", \"features.2.1.block.3.0.weight\", \"features.2.1.block.3.1.weight\", \"features.2.1.block.3.1.bias\", \"features.2.1.block.3.1.running_mean\", \"features.2.1.block.3.1.running_var\", \"features.2.2.block.0.0.weight\", \"features.2.2.block.0.1.weight\", \"features.2.2.block.0.1.bias\", \"features.2.2.block.0.1.running_mean\", \"features.2.2.block.0.1.running_var\", \"features.2.2.block.1.0.weight\", \"features.2.2.block.1.1.weight\", \"features.2.2.block.1.1.bias\", \"features.2.2.block.1.1.running_mean\", \"features.2.2.block.1.1.running_var\", \"features.2.2.block.2.fc1.weight\", \"features.2.2.block.2.fc1.bias\", \"features.2.2.block.2.fc2.weight\", \"features.2.2.block.2.fc2.bias\", \"features.2.2.block.3.0.weight\", \"features.2.2.block.3.1.weight\", \"features.2.2.block.3.1.bias\", \"features.2.2.block.3.1.running_mean\", \"features.2.2.block.3.1.running_var\", \"features.3.0.block.0.0.weight\", \"features.3.0.block.0.1.weight\", \"features.3.0.block.0.1.bias\", \"features.3.0.block.0.1.running_mean\", \"features.3.0.block.0.1.running_var\", \"features.3.0.block.1.0.weight\", \"features.3.0.block.1.1.weight\", \"features.3.0.block.1.1.bias\", \"features.3.0.block.1.1.running_mean\", \"features.3.0.block.1.1.running_var\", \"features.3.0.block.2.fc1.weight\", \"features.3.0.block.2.fc1.bias\", \"features.3.0.block.2.fc2.weight\", \"features.3.0.block.2.fc2.bias\", \"features.3.0.block.3.0.weight\", \"features.3.0.block.3.1.weight\", \"features.3.0.block.3.1.bias\", \"features.3.0.block.3.1.running_mean\", \"features.3.0.block.3.1.running_var\", \"features.3.1.block.0.0.weight\", \"features.3.1.block.0.1.weight\", \"features.3.1.block.0.1.bias\", \"features.3.1.block.0.1.running_mean\", \"features.3.1.block.0.1.running_var\", \"features.3.1.block.1.0.weight\", \"features.3.1.block.1.1.weight\", \"features.3.1.block.1.1.bias\", \"features.3.1.block.1.1.running_mean\", \"features.3.1.block.1.1.running_var\", \"features.3.1.block.2.fc1.weight\", \"features.3.1.block.2.fc1.bias\", \"features.3.1.block.2.fc2.weight\", \"features.3.1.block.2.fc2.bias\", \"features.3.1.block.3.0.weight\", \"features.3.1.block.3.1.weight\", \"features.3.1.block.3.1.bias\", \"features.3.1.block.3.1.running_mean\", \"features.3.1.block.3.1.running_var\", \"features.3.2.block.0.0.weight\", \"features.3.2.block.0.1.weight\", \"features.3.2.block.0.1.bias\", \"features.3.2.block.0.1.running_mean\", \"features.3.2.block.0.1.running_var\", \"features.3.2.block.1.0.weight\", \"features.3.2.block.1.1.weight\", \"features.3.2.block.1.1.bias\", \"features.3.2.block.1.1.running_mean\", \"features.3.2.block.1.1.running_var\", \"features.3.2.block.2.fc1.weight\", \"features.3.2.block.2.fc1.bias\", \"features.3.2.block.2.fc2.weight\", \"features.3.2.block.2.fc2.bias\", \"features.3.2.block.3.0.weight\", \"features.3.2.block.3.1.weight\", \"features.3.2.block.3.1.bias\", \"features.3.2.block.3.1.running_mean\", \"features.3.2.block.3.1.running_var\", \"features.4.0.block.0.0.weight\", \"features.4.0.block.0.1.weight\", \"features.4.0.block.0.1.bias\", \"features.4.0.block.0.1.running_mean\", \"features.4.0.block.0.1.running_var\", \"features.4.0.block.1.0.weight\", \"features.4.0.block.1.1.weight\", \"features.4.0.block.1.1.bias\", \"features.4.0.block.1.1.running_mean\", \"features.4.0.block.1.1.running_var\", \"features.4.0.block.2.fc1.weight\", \"features.4.0.block.2.fc1.bias\", \"features.4.0.block.2.fc2.weight\", \"features.4.0.block.2.fc2.bias\", \"features.4.0.block.3.0.weight\", \"features.4.0.block.3.1.weight\", \"features.4.0.block.3.1.bias\", \"features.4.0.block.3.1.running_mean\", \"features.4.0.block.3.1.running_var\", \"features.4.1.block.0.0.weight\", \"features.4.1.block.0.1.weight\", \"features.4.1.block.0.1.bias\", \"features.4.1.block.0.1.running_mean\", \"features.4.1.block.0.1.running_var\", \"features.4.1.block.1.0.weight\", \"features.4.1.block.1.1.weight\", \"features.4.1.block.1.1.bias\", \"features.4.1.block.1.1.running_mean\", \"features.4.1.block.1.1.running_var\", \"features.4.1.block.2.fc1.weight\", \"features.4.1.block.2.fc1.bias\", \"features.4.1.block.2.fc2.weight\", \"features.4.1.block.2.fc2.bias\", \"features.4.1.block.3.0.weight\", \"features.4.1.block.3.1.weight\", \"features.4.1.block.3.1.bias\", \"features.4.1.block.3.1.running_mean\", \"features.4.1.block.3.1.running_var\", \"features.4.2.block.0.0.weight\", \"features.4.2.block.0.1.weight\", \"features.4.2.block.0.1.bias\", \"features.4.2.block.0.1.running_mean\", \"features.4.2.block.0.1.running_var\", \"features.4.2.block.1.0.weight\", \"features.4.2.block.1.1.weight\", \"features.4.2.block.1.1.bias\", \"features.4.2.block.1.1.running_mean\", \"features.4.2.block.1.1.running_var\", \"features.4.2.block.2.fc1.weight\", \"features.4.2.block.2.fc1.bias\", \"features.4.2.block.2.fc2.weight\", \"features.4.2.block.2.fc2.bias\", \"features.4.2.block.3.0.weight\", \"features.4.2.block.3.1.weight\", \"features.4.2.block.3.1.bias\", \"features.4.2.block.3.1.running_mean\", \"features.4.2.block.3.1.running_var\", \"features.4.3.block.0.0.weight\", \"features.4.3.block.0.1.weight\", \"features.4.3.block.0.1.bias\", \"features.4.3.block.0.1.running_mean\", \"features.4.3.block.0.1.running_var\", \"features.4.3.block.1.0.weight\", \"features.4.3.block.1.1.weight\", \"features.4.3.block.1.1.bias\", \"features.4.3.block.1.1.running_mean\", \"features.4.3.block.1.1.running_var\", \"features.4.3.block.2.fc1.weight\", \"features.4.3.block.2.fc1.bias\", \"features.4.3.block.2.fc2.weight\", \"features.4.3.block.2.fc2.bias\", \"features.4.3.block.3.0.weight\", \"features.4.3.block.3.1.weight\", \"features.4.3.block.3.1.bias\", \"features.4.3.block.3.1.running_mean\", \"features.4.3.block.3.1.running_var\", \"features.5.0.block.0.0.weight\", \"features.5.0.block.0.1.weight\", \"features.5.0.block.0.1.bias\", \"features.5.0.block.0.1.running_mean\", \"features.5.0.block.0.1.running_var\", \"features.5.0.block.1.0.weight\", \"features.5.0.block.1.1.weight\", \"features.5.0.block.1.1.bias\", \"features.5.0.block.1.1.running_mean\", \"features.5.0.block.1.1.running_var\", \"features.5.0.block.2.fc1.weight\", \"features.5.0.block.2.fc1.bias\", \"features.5.0.block.2.fc2.weight\", \"features.5.0.block.2.fc2.bias\", \"features.5.0.block.3.0.weight\", \"features.5.0.block.3.1.weight\", \"features.5.0.block.3.1.bias\", \"features.5.0.block.3.1.running_mean\", \"features.5.0.block.3.1.running_var\", \"features.5.1.block.0.0.weight\", \"features.5.1.block.0.1.weight\", \"features.5.1.block.0.1.bias\", \"features.5.1.block.0.1.running_mean\", \"features.5.1.block.0.1.running_var\", \"features.5.1.block.1.0.weight\", \"features.5.1.block.1.1.weight\", \"features.5.1.block.1.1.bias\", \"features.5.1.block.1.1.running_mean\", \"features.5.1.block.1.1.running_var\", \"features.5.1.block.2.fc1.weight\", \"features.5.1.block.2.fc1.bias\", \"features.5.1.block.2.fc2.weight\", \"features.5.1.block.2.fc2.bias\", \"features.5.1.block.3.0.weight\", \"features.5.1.block.3.1.weight\", \"features.5.1.block.3.1.bias\", \"features.5.1.block.3.1.running_mean\", \"features.5.1.block.3.1.running_var\", \"features.5.2.block.0.0.weight\", \"features.5.2.block.0.1.weight\", \"features.5.2.block.0.1.bias\", \"features.5.2.block.0.1.running_mean\", \"features.5.2.block.0.1.running_var\", \"features.5.2.block.1.0.weight\", \"features.5.2.block.1.1.weight\", \"features.5.2.block.1.1.bias\", \"features.5.2.block.1.1.running_mean\", \"features.5.2.block.1.1.running_var\", \"features.5.2.block.2.fc1.weight\", \"features.5.2.block.2.fc1.bias\", \"features.5.2.block.2.fc2.weight\", \"features.5.2.block.2.fc2.bias\", \"features.5.2.block.3.0.weight\", \"features.5.2.block.3.1.weight\", \"features.5.2.block.3.1.bias\", \"features.5.2.block.3.1.running_mean\", \"features.5.2.block.3.1.running_var\", \"features.5.3.block.0.0.weight\", \"features.5.3.block.0.1.weight\", \"features.5.3.block.0.1.bias\", \"features.5.3.block.0.1.running_mean\", \"features.5.3.block.0.1.running_var\", \"features.5.3.block.1.0.weight\", \"features.5.3.block.1.1.weight\", \"features.5.3.block.1.1.bias\", \"features.5.3.block.1.1.running_mean\", \"features.5.3.block.1.1.running_var\", \"features.5.3.block.2.fc1.weight\", \"features.5.3.block.2.fc1.bias\", \"features.5.3.block.2.fc2.weight\", \"features.5.3.block.2.fc2.bias\", \"features.5.3.block.3.0.weight\", \"features.5.3.block.3.1.weight\", \"features.5.3.block.3.1.bias\", \"features.5.3.block.3.1.running_mean\", \"features.5.3.block.3.1.running_var\", \"features.6.0.block.0.0.weight\", \"features.6.0.block.0.1.weight\", \"features.6.0.block.0.1.bias\", \"features.6.0.block.0.1.running_mean\", \"features.6.0.block.0.1.running_var\", \"features.6.0.block.1.0.weight\", \"features.6.0.block.1.1.weight\", \"features.6.0.block.1.1.bias\", \"features.6.0.block.1.1.running_mean\", \"features.6.0.block.1.1.running_var\", \"features.6.0.block.2.fc1.weight\", \"features.6.0.block.2.fc1.bias\", \"features.6.0.block.2.fc2.weight\", \"features.6.0.block.2.fc2.bias\", \"features.6.0.block.3.0.weight\", \"features.6.0.block.3.1.weight\", \"features.6.0.block.3.1.bias\", \"features.6.0.block.3.1.running_mean\", \"features.6.0.block.3.1.running_var\", \"features.6.1.block.0.0.weight\", \"features.6.1.block.0.1.weight\", \"features.6.1.block.0.1.bias\", \"features.6.1.block.0.1.running_mean\", \"features.6.1.block.0.1.running_var\", \"features.6.1.block.1.0.weight\", \"features.6.1.block.1.1.weight\", \"features.6.1.block.1.1.bias\", \"features.6.1.block.1.1.running_mean\", \"features.6.1.block.1.1.running_var\", \"features.6.1.block.2.fc1.weight\", \"features.6.1.block.2.fc1.bias\", \"features.6.1.block.2.fc2.weight\", \"features.6.1.block.2.fc2.bias\", \"features.6.1.block.3.0.weight\", \"features.6.1.block.3.1.weight\", \"features.6.1.block.3.1.bias\", \"features.6.1.block.3.1.running_mean\", \"features.6.1.block.3.1.running_var\", \"features.6.2.block.0.0.weight\", \"features.6.2.block.0.1.weight\", \"features.6.2.block.0.1.bias\", \"features.6.2.block.0.1.running_mean\", \"features.6.2.block.0.1.running_var\", \"features.6.2.block.1.0.weight\", \"features.6.2.block.1.1.weight\", \"features.6.2.block.1.1.bias\", \"features.6.2.block.1.1.running_mean\", \"features.6.2.block.1.1.running_var\", \"features.6.2.block.2.fc1.weight\", \"features.6.2.block.2.fc1.bias\", \"features.6.2.block.2.fc2.weight\", \"features.6.2.block.2.fc2.bias\", \"features.6.2.block.3.0.weight\", \"features.6.2.block.3.1.weight\", \"features.6.2.block.3.1.bias\", \"features.6.2.block.3.1.running_mean\", \"features.6.2.block.3.1.running_var\", \"features.6.3.block.0.0.weight\", \"features.6.3.block.0.1.weight\", \"features.6.3.block.0.1.bias\", \"features.6.3.block.0.1.running_mean\", \"features.6.3.block.0.1.running_var\", \"features.6.3.block.1.0.weight\", \"features.6.3.block.1.1.weight\", \"features.6.3.block.1.1.bias\", \"features.6.3.block.1.1.running_mean\", \"features.6.3.block.1.1.running_var\", \"features.6.3.block.2.fc1.weight\", \"features.6.3.block.2.fc1.bias\", \"features.6.3.block.2.fc2.weight\", \"features.6.3.block.2.fc2.bias\", \"features.6.3.block.3.0.weight\", \"features.6.3.block.3.1.weight\", \"features.6.3.block.3.1.bias\", \"features.6.3.block.3.1.running_mean\", \"features.6.3.block.3.1.running_var\", \"features.6.4.block.0.0.weight\", \"features.6.4.block.0.1.weight\", \"features.6.4.block.0.1.bias\", \"features.6.4.block.0.1.running_mean\", \"features.6.4.block.0.1.running_var\", \"features.6.4.block.1.0.weight\", \"features.6.4.block.1.1.weight\", \"features.6.4.block.1.1.bias\", \"features.6.4.block.1.1.running_mean\", \"features.6.4.block.1.1.running_var\", \"features.6.4.block.2.fc1.weight\", \"features.6.4.block.2.fc1.bias\", \"features.6.4.block.2.fc2.weight\", \"features.6.4.block.2.fc2.bias\", \"features.6.4.block.3.0.weight\", \"features.6.4.block.3.1.weight\", \"features.6.4.block.3.1.bias\", \"features.6.4.block.3.1.running_mean\", \"features.6.4.block.3.1.running_var\", \"features.7.0.block.0.0.weight\", \"features.7.0.block.0.1.weight\", \"features.7.0.block.0.1.bias\", \"features.7.0.block.0.1.running_mean\", \"features.7.0.block.0.1.running_var\", \"features.7.0.block.1.0.weight\", \"features.7.0.block.1.1.weight\", \"features.7.0.block.1.1.bias\", \"features.7.0.block.1.1.running_mean\", \"features.7.0.block.1.1.running_var\", \"features.7.0.block.2.fc1.weight\", \"features.7.0.block.2.fc1.bias\", \"features.7.0.block.2.fc2.weight\", \"features.7.0.block.2.fc2.bias\", \"features.7.0.block.3.0.weight\", \"features.7.0.block.3.1.weight\", \"features.7.0.block.3.1.bias\", \"features.7.0.block.3.1.running_mean\", \"features.7.0.block.3.1.running_var\", \"features.7.1.block.0.0.weight\", \"features.7.1.block.0.1.weight\", \"features.7.1.block.0.1.bias\", \"features.7.1.block.0.1.running_mean\", \"features.7.1.block.0.1.running_var\", \"features.7.1.block.1.0.weight\", \"features.7.1.block.1.1.weight\", \"features.7.1.block.1.1.bias\", \"features.7.1.block.1.1.running_mean\", \"features.7.1.block.1.1.running_var\", \"features.7.1.block.2.fc1.weight\", \"features.7.1.block.2.fc1.bias\", \"features.7.1.block.2.fc2.weight\", \"features.7.1.block.2.fc2.bias\", \"features.7.1.block.3.0.weight\", \"features.7.1.block.3.1.weight\", \"features.7.1.block.3.1.bias\", \"features.7.1.block.3.1.running_mean\", \"features.7.1.block.3.1.running_var\", \"features.8.0.weight\", \"features.8.1.weight\", \"features.8.1.bias\", \"features.8.1.running_mean\", \"features.8.1.running_var\", \"classifier.1.weight\", \"classifier.1.bias\". \n\tUnexpected key(s) in state_dict: \"encoder.inc.conv.conv.0.weight\", \"encoder.inc.conv.conv.0.bias\", \"encoder.inc.conv.conv.1.weight\", \"encoder.inc.conv.conv.1.bias\", \"encoder.inc.conv.conv.1.running_mean\", \"encoder.inc.conv.conv.1.running_var\", \"encoder.inc.conv.conv.1.num_batches_tracked\", \"encoder.inc.conv.conv.3.weight\", \"encoder.inc.conv.conv.3.bias\", \"encoder.inc.conv.conv.4.weight\", \"encoder.inc.conv.conv.4.bias\", \"encoder.inc.conv.conv.4.running_mean\", \"encoder.inc.conv.conv.4.running_var\", \"encoder.inc.conv.conv.4.num_batches_tracked\", \"encoder.down1.mpconv.1.conv.0.weight\", \"encoder.down1.mpconv.1.conv.0.bias\", \"encoder.down1.mpconv.1.conv.1.weight\", \"encoder.down1.mpconv.1.conv.1.bias\", \"encoder.down1.mpconv.1.conv.1.running_mean\", \"encoder.down1.mpconv.1.conv.1.running_var\", \"encoder.down1.mpconv.1.conv.1.num_batches_tracked\", \"encoder.down1.mpconv.1.conv.3.weight\", \"encoder.down1.mpconv.1.conv.3.bias\", \"encoder.down1.mpconv.1.conv.4.weight\", \"encoder.down1.mpconv.1.conv.4.bias\", \"encoder.down1.mpconv.1.conv.4.running_mean\", \"encoder.down1.mpconv.1.conv.4.running_var\", \"encoder.down1.mpconv.1.conv.4.num_batches_tracked\", \"encoder.down2.mpconv.1.conv.0.weight\", \"encoder.down2.mpconv.1.conv.0.bias\", \"encoder.down2.mpconv.1.conv.1.weight\", \"encoder.down2.mpconv.1.conv.1.bias\", \"encoder.down2.mpconv.1.conv.1.running_mean\", \"encoder.down2.mpconv.1.conv.1.running_var\", \"encoder.down2.mpconv.1.conv.1.num_batches_tracked\", \"encoder.down2.mpconv.1.conv.3.weight\", \"encoder.down2.mpconv.1.conv.3.bias\", \"encoder.down2.mpconv.1.conv.4.weight\", \"encoder.down2.mpconv.1.conv.4.bias\", \"encoder.down2.mpconv.1.conv.4.running_mean\", \"encoder.down2.mpconv.1.conv.4.running_var\", \"encoder.down2.mpconv.1.conv.4.num_batches_tracked\", \"encoder.down3.mpconv.1.conv.0.weight\", \"encoder.down3.mpconv.1.conv.0.bias\", \"encoder.down3.mpconv.1.conv.1.weight\", \"encoder.down3.mpconv.1.conv.1.bias\", \"encoder.down3.mpconv.1.conv.1.running_mean\", \"encoder.down3.mpconv.1.conv.1.running_var\", \"encoder.down3.mpconv.1.conv.1.num_batches_tracked\", \"encoder.down3.mpconv.1.conv.3.weight\", \"encoder.down3.mpconv.1.conv.3.bias\", \"encoder.down3.mpconv.1.conv.4.weight\", \"encoder.down3.mpconv.1.conv.4.bias\", \"encoder.down3.mpconv.1.conv.4.running_mean\", \"encoder.down3.mpconv.1.conv.4.running_var\", \"encoder.down3.mpconv.1.conv.4.num_batches_tracked\", \"encoder.down4.mpconv.1.conv.0.weight\", \"encoder.down4.mpconv.1.conv.0.bias\", \"encoder.down4.mpconv.1.conv.1.weight\", \"encoder.down4.mpconv.1.conv.1.bias\", \"encoder.down4.mpconv.1.conv.1.running_mean\", \"encoder.down4.mpconv.1.conv.1.running_var\", \"encoder.down4.mpconv.1.conv.1.num_batches_tracked\", \"encoder.down4.mpconv.1.conv.3.weight\", \"encoder.down4.mpconv.1.conv.3.bias\", \"encoder.down4.mpconv.1.conv.4.weight\", \"encoder.down4.mpconv.1.conv.4.bias\", \"encoder.down4.mpconv.1.conv.4.running_mean\", \"encoder.down4.mpconv.1.conv.4.running_var\", \"encoder.down4.mpconv.1.conv.4.num_batches_tracked\", \"cnn.features.0.0.weight\", \"cnn.features.0.1.weight\", \"cnn.features.0.1.bias\", \"cnn.features.0.1.running_mean\", \"cnn.features.0.1.running_var\", \"cnn.features.0.1.num_batches_tracked\", \"cnn.features.1.0.block.0.0.weight\", \"cnn.features.1.0.block.0.1.weight\", \"cnn.features.1.0.block.0.1.bias\", \"cnn.features.1.0.block.0.1.running_mean\", \"cnn.features.1.0.block.0.1.running_var\", \"cnn.features.1.0.block.0.1.num_batches_tracked\", \"cnn.features.1.0.block.1.fc1.weight\", \"cnn.features.1.0.block.1.fc1.bias\", \"cnn.features.1.0.block.1.fc2.weight\", \"cnn.features.1.0.block.1.fc2.bias\", \"cnn.features.1.0.block.2.0.weight\", \"cnn.features.1.0.block.2.1.weight\", \"cnn.features.1.0.block.2.1.bias\", \"cnn.features.1.0.block.2.1.running_mean\", \"cnn.features.1.0.block.2.1.running_var\", \"cnn.features.1.0.block.2.1.num_batches_tracked\", \"cnn.features.1.1.block.0.0.weight\", \"cnn.features.1.1.block.0.1.weight\", \"cnn.features.1.1.block.0.1.bias\", \"cnn.features.1.1.block.0.1.running_mean\", \"cnn.features.1.1.block.0.1.running_var\", \"cnn.features.1.1.block.0.1.num_batches_tracked\", \"cnn.features.1.1.block.1.fc1.weight\", \"cnn.features.1.1.block.1.fc1.bias\", \"cnn.features.1.1.block.1.fc2.weight\", \"cnn.features.1.1.block.1.fc2.bias\", \"cnn.features.1.1.block.2.0.weight\", \"cnn.features.1.1.block.2.1.weight\", \"cnn.features.1.1.block.2.1.bias\", \"cnn.features.1.1.block.2.1.running_mean\", \"cnn.features.1.1.block.2.1.running_var\", \"cnn.features.1.1.block.2.1.num_batches_tracked\", \"cnn.features.2.0.block.0.0.weight\", \"cnn.features.2.0.block.0.1.weight\", \"cnn.features.2.0.block.0.1.bias\", \"cnn.features.2.0.block.0.1.running_mean\", \"cnn.features.2.0.block.0.1.running_var\", \"cnn.features.2.0.block.0.1.num_batches_tracked\", \"cnn.features.2.0.block.1.0.weight\", \"cnn.features.2.0.block.1.1.weight\", \"cnn.features.2.0.block.1.1.bias\", \"cnn.features.2.0.block.1.1.running_mean\", \"cnn.features.2.0.block.1.1.running_var\", \"cnn.features.2.0.block.1.1.num_batches_tracked\", \"cnn.features.2.0.block.2.fc1.weight\", \"cnn.features.2.0.block.2.fc1.bias\", \"cnn.features.2.0.block.2.fc2.weight\", \"cnn.features.2.0.block.2.fc2.bias\", \"cnn.features.2.0.block.3.0.weight\", \"cnn.features.2.0.block.3.1.weight\", \"cnn.features.2.0.block.3.1.bias\", \"cnn.features.2.0.block.3.1.running_mean\", \"cnn.features.2.0.block.3.1.running_var\", \"cnn.features.2.0.block.3.1.num_batches_tracked\", \"cnn.features.2.1.block.0.0.weight\", \"cnn.features.2.1.block.0.1.weight\", \"cnn.features.2.1.block.0.1.bias\", \"cnn.features.2.1.block.0.1.running_mean\", \"cnn.features.2.1.block.0.1.running_var\", \"cnn.features.2.1.block.0.1.num_batches_tracked\", \"cnn.features.2.1.block.1.0.weight\", \"cnn.features.2.1.block.1.1.weight\", \"cnn.features.2.1.block.1.1.bias\", \"cnn.features.2.1.block.1.1.running_mean\", \"cnn.features.2.1.block.1.1.running_var\", \"cnn.features.2.1.block.1.1.num_batches_tracked\", \"cnn.features.2.1.block.2.fc1.weight\", \"cnn.features.2.1.block.2.fc1.bias\", \"cnn.features.2.1.block.2.fc2.weight\", \"cnn.features.2.1.block.2.fc2.bias\", \"cnn.features.2.1.block.3.0.weight\", \"cnn.features.2.1.block.3.1.weight\", \"cnn.features.2.1.block.3.1.bias\", \"cnn.features.2.1.block.3.1.running_mean\", \"cnn.features.2.1.block.3.1.running_var\", \"cnn.features.2.1.block.3.1.num_batches_tracked\", \"cnn.features.2.2.block.0.0.weight\", \"cnn.features.2.2.block.0.1.weight\", \"cnn.features.2.2.block.0.1.bias\", \"cnn.features.2.2.block.0.1.running_mean\", \"cnn.features.2.2.block.0.1.running_var\", \"cnn.features.2.2.block.0.1.num_batches_tracked\", \"cnn.features.2.2.block.1.0.weight\", \"cnn.features.2.2.block.1.1.weight\", \"cnn.features.2.2.block.1.1.bias\", \"cnn.features.2.2.block.1.1.running_mean\", \"cnn.features.2.2.block.1.1.running_var\", \"cnn.features.2.2.block.1.1.num_batches_tracked\", \"cnn.features.2.2.block.2.fc1.weight\", \"cnn.features.2.2.block.2.fc1.bias\", \"cnn.features.2.2.block.2.fc2.weight\", \"cnn.features.2.2.block.2.fc2.bias\", \"cnn.features.2.2.block.3.0.weight\", \"cnn.features.2.2.block.3.1.weight\", \"cnn.features.2.2.block.3.1.bias\", \"cnn.features.2.2.block.3.1.running_mean\", \"cnn.features.2.2.block.3.1.running_var\", \"cnn.features.2.2.block.3.1.num_batches_tracked\", \"cnn.features.3.0.block.0.0.weight\", \"cnn.features.3.0.block.0.1.weight\", \"cnn.features.3.0.block.0.1.bias\", \"cnn.features.3.0.block.0.1.running_mean\", \"cnn.features.3.0.block.0.1.running_var\", \"cnn.features.3.0.block.0.1.num_batches_tracked\", \"cnn.features.3.0.block.1.0.weight\", \"cnn.features.3.0.block.1.1.weight\", \"cnn.features.3.0.block.1.1.bias\", \"cnn.features.3.0.block.1.1.running_mean\", \"cnn.features.3.0.block.1.1.running_var\", \"cnn.features.3.0.block.1.1.num_batches_tracked\", \"cnn.features.3.0.block.2.fc1.weight\", \"cnn.features.3.0.block.2.fc1.bias\", \"cnn.features.3.0.block.2.fc2.weight\", \"cnn.features.3.0.block.2.fc2.bias\", \"cnn.features.3.0.block.3.0.weight\", \"cnn.features.3.0.block.3.1.weight\", \"cnn.features.3.0.block.3.1.bias\", \"cnn.features.3.0.block.3.1.running_mean\", \"cnn.features.3.0.block.3.1.running_var\", \"cnn.features.3.0.block.3.1.num_batches_tracked\", \"cnn.features.3.1.block.0.0.weight\", \"cnn.features.3.1.block.0.1.weight\", \"cnn.features.3.1.block.0.1.bias\", \"cnn.features.3.1.block.0.1.running_mean\", \"cnn.features.3.1.block.0.1.running_var\", \"cnn.features.3.1.block.0.1.num_batches_tracked\", \"cnn.features.3.1.block.1.0.weight\", \"cnn.features.3.1.block.1.1.weight\", \"cnn.features.3.1.block.1.1.bias\", \"cnn.features.3.1.block.1.1.running_mean\", \"cnn.features.3.1.block.1.1.running_var\", \"cnn.features.3.1.block.1.1.num_batches_tracked\", \"cnn.features.3.1.block.2.fc1.weight\", \"cnn.features.3.1.block.2.fc1.bias\", \"cnn.features.3.1.block.2.fc2.weight\", \"cnn.features.3.1.block.2.fc2.bias\", \"cnn.features.3.1.block.3.0.weight\", \"cnn.features.3.1.block.3.1.weight\", \"cnn.features.3.1.block.3.1.bias\", \"cnn.features.3.1.block.3.1.running_mean\", \"cnn.features.3.1.block.3.1.running_var\", \"cnn.features.3.1.block.3.1.num_batches_tracked\", \"cnn.features.3.2.block.0.0.weight\", \"cnn.features.3.2.block.0.1.weight\", \"cnn.features.3.2.block.0.1.bias\", \"cnn.features.3.2.block.0.1.running_mean\", \"cnn.features.3.2.block.0.1.running_var\", \"cnn.features.3.2.block.0.1.num_batches_tracked\", \"cnn.features.3.2.block.1.0.weight\", \"cnn.features.3.2.block.1.1.weight\", \"cnn.features.3.2.block.1.1.bias\", \"cnn.features.3.2.block.1.1.running_mean\", \"cnn.features.3.2.block.1.1.running_var\", \"cnn.features.3.2.block.1.1.num_batches_tracked\", \"cnn.features.3.2.block.2.fc1.weight\", \"cnn.features.3.2.block.2.fc1.bias\", \"cnn.features.3.2.block.2.fc2.weight\", \"cnn.features.3.2.block.2.fc2.bias\", \"cnn.features.3.2.block.3.0.weight\", \"cnn.features.3.2.block.3.1.weight\", \"cnn.features.3.2.block.3.1.bias\", \"cnn.features.3.2.block.3.1.running_mean\", \"cnn.features.3.2.block.3.1.running_var\", \"cnn.features.3.2.block.3.1.num_batches_tracked\", \"cnn.features.4.0.block.0.0.weight\", \"cnn.features.4.0.block.0.1.weight\", \"cnn.features.4.0.block.0.1.bias\", \"cnn.features.4.0.block.0.1.running_mean\", \"cnn.features.4.0.block.0.1.running_var\", \"cnn.features.4.0.block.0.1.num_batches_tracked\", \"cnn.features.4.0.block.1.0.weight\", \"cnn.features.4.0.block.1.1.weight\", \"cnn.features.4.0.block.1.1.bias\", \"cnn.features.4.0.block.1.1.running_mean\", \"cnn.features.4.0.block.1.1.running_var\", \"cnn.features.4.0.block.1.1.num_batches_tracked\", \"cnn.features.4.0.block.2.fc1.weight\", \"cnn.features.4.0.block.2.fc1.bias\", \"cnn.features.4.0.block.2.fc2.weight\", \"cnn.features.4.0.block.2.fc2.bias\", \"cnn.features.4.0.block.3.0.weight\", \"cnn.features.4.0.block.3.1.weight\", \"cnn.features.4.0.block.3.1.bias\", \"cnn.features.4.0.block.3.1.running_mean\", \"cnn.features.4.0.block.3.1.running_var\", \"cnn.features.4.0.block.3.1.num_batches_tracked\", \"cnn.features.4.1.block.0.0.weight\", \"cnn.features.4.1.block.0.1.weight\", \"cnn.features.4.1.block.0.1.bias\", \"cnn.features.4.1.block.0.1.running_mean\", \"cnn.features.4.1.block.0.1.running_var\", \"cnn.features.4.1.block.0.1.num_batches_tracked\", \"cnn.features.4.1.block.1.0.weight\", \"cnn.features.4.1.block.1.1.weight\", \"cnn.features.4.1.block.1.1.bias\", \"cnn.features.4.1.block.1.1.running_mean\", \"cnn.features.4.1.block.1.1.running_var\", \"cnn.features.4.1.block.1.1.num_batches_tracked\", \"cnn.features.4.1.block.2.fc1.weight\", \"cnn.features.4.1.block.2.fc1.bias\", \"cnn.features.4.1.block.2.fc2.weight\", \"cnn.features.4.1.block.2.fc2.bias\", \"cnn.features.4.1.block.3.0.weight\", \"cnn.features.4.1.block.3.1.weight\", \"cnn.features.4.1.block.3.1.bias\", \"cnn.features.4.1.block.3.1.running_mean\", \"cnn.features.4.1.block.3.1.running_var\", \"cnn.features.4.1.block.3.1.num_batches_tracked\", \"cnn.features.4.2.block.0.0.weight\", \"cnn.features.4.2.block.0.1.weight\", \"cnn.features.4.2.block.0.1.bias\", \"cnn.features.4.2.block.0.1.running_mean\", \"cnn.features.4.2.block.0.1.running_var\", \"cnn.features.4.2.block.0.1.num_batches_tracked\", \"cnn.features.4.2.block.1.0.weight\", \"cnn.features.4.2.block.1.1.weight\", \"cnn.features.4.2.block.1.1.bias\", \"cnn.features.4.2.block.1.1.running_mean\", \"cnn.features.4.2.block.1.1.running_var\", \"cnn.features.4.2.block.1.1.num_batches_tracked\", \"cnn.features.4.2.block.2.fc1.weight\", \"cnn.features.4.2.block.2.fc1.bias\", \"cnn.features.4.2.block.2.fc2.weight\", \"cnn.features.4.2.block.2.fc2.bias\", \"cnn.features.4.2.block.3.0.weight\", \"cnn.features.4.2.block.3.1.weight\", \"cnn.features.4.2.block.3.1.bias\", \"cnn.features.4.2.block.3.1.running_mean\", \"cnn.features.4.2.block.3.1.running_var\", \"cnn.features.4.2.block.3.1.num_batches_tracked\", \"cnn.features.4.3.block.0.0.weight\", \"cnn.features.4.3.block.0.1.weight\", \"cnn.features.4.3.block.0.1.bias\", \"cnn.features.4.3.block.0.1.running_mean\", \"cnn.features.4.3.block.0.1.running_var\", \"cnn.features.4.3.block.0.1.num_batches_tracked\", \"cnn.features.4.3.block.1.0.weight\", \"cnn.features.4.3.block.1.1.weight\", \"cnn.features.4.3.block.1.1.bias\", \"cnn.features.4.3.block.1.1.running_mean\", \"cnn.features.4.3.block.1.1.running_var\", \"cnn.features.4.3.block.1.1.num_batches_tracked\", \"cnn.features.4.3.block.2.fc1.weight\", \"cnn.features.4.3.block.2.fc1.bias\", \"cnn.features.4.3.block.2.fc2.weight\", \"cnn.features.4.3.block.2.fc2.bias\", \"cnn.features.4.3.block.3.0.weight\", \"cnn.features.4.3.block.3.1.weight\", \"cnn.features.4.3.block.3.1.bias\", \"cnn.features.4.3.block.3.1.running_mean\", \"cnn.features.4.3.block.3.1.running_var\", \"cnn.features.4.3.block.3.1.num_batches_tracked\", \"cnn.features.5.0.block.0.0.weight\", \"cnn.features.5.0.block.0.1.weight\", \"cnn.features.5.0.block.0.1.bias\", \"cnn.features.5.0.block.0.1.running_mean\", \"cnn.features.5.0.block.0.1.running_var\", \"cnn.features.5.0.block.0.1.num_batches_tracked\", \"cnn.features.5.0.block.1.0.weight\", \"cnn.features.5.0.block.1.1.weight\", \"cnn.features.5.0.block.1.1.bias\", \"cnn.features.5.0.block.1.1.running_mean\", \"cnn.features.5.0.block.1.1.running_var\", \"cnn.features.5.0.block.1.1.num_batches_tracked\", \"cnn.features.5.0.block.2.fc1.weight\", \"cnn.features.5.0.block.2.fc1.bias\", \"cnn.features.5.0.block.2.fc2.weight\", \"cnn.features.5.0.block.2.fc2.bias\", \"cnn.features.5.0.block.3.0.weight\", \"cnn.features.5.0.block.3.1.weight\", \"cnn.features.5.0.block.3.1.bias\", \"cnn.features.5.0.block.3.1.running_mean\", \"cnn.features.5.0.block.3.1.running_var\", \"cnn.features.5.0.block.3.1.num_batches_tracked\", \"cnn.features.5.1.block.0.0.weight\", \"cnn.features.5.1.block.0.1.weight\", \"cnn.features.5.1.block.0.1.bias\", \"cnn.features.5.1.block.0.1.running_mean\", \"cnn.features.5.1.block.0.1.running_var\", \"cnn.features.5.1.block.0.1.num_batches_tracked\", \"cnn.features.5.1.block.1.0.weight\", \"cnn.features.5.1.block.1.1.weight\", \"cnn.features.5.1.block.1.1.bias\", \"cnn.features.5.1.block.1.1.running_mean\", \"cnn.features.5.1.block.1.1.running_var\", \"cnn.features.5.1.block.1.1.num_batches_tracked\", \"cnn.features.5.1.block.2.fc1.weight\", \"cnn.features.5.1.block.2.fc1.bias\", \"cnn.features.5.1.block.2.fc2.weight\", \"cnn.features.5.1.block.2.fc2.bias\", \"cnn.features.5.1.block.3.0.weight\", \"cnn.features.5.1.block.3.1.weight\", \"cnn.features.5.1.block.3.1.bias\", \"cnn.features.5.1.block.3.1.running_mean\", \"cnn.features.5.1.block.3.1.running_var\", \"cnn.features.5.1.block.3.1.num_batches_tracked\", \"cnn.features.5.2.block.0.0.weight\", \"cnn.features.5.2.block.0.1.weight\", \"cnn.features.5.2.block.0.1.bias\", \"cnn.features.5.2.block.0.1.running_mean\", \"cnn.features.5.2.block.0.1.running_var\", \"cnn.features.5.2.block.0.1.num_batches_tracked\", \"cnn.features.5.2.block.1.0.weight\", \"cnn.features.5.2.block.1.1.weight\", \"cnn.features.5.2.block.1.1.bias\", \"cnn.features.5.2.block.1.1.running_mean\", \"cnn.features.5.2.block.1.1.running_var\", \"cnn.features.5.2.block.1.1.num_batches_tracked\", \"cnn.features.5.2.block.2.fc1.weight\", \"cnn.features.5.2.block.2.fc1.bias\", \"cnn.features.5.2.block.2.fc2.weight\", \"cnn.features.5.2.block.2.fc2.bias\", \"cnn.features.5.2.block.3.0.weight\", \"cnn.features.5.2.block.3.1.weight\", \"cnn.features.5.2.block.3.1.bias\", \"cnn.features.5.2.block.3.1.running_mean\", \"cnn.features.5.2.block.3.1.running_var\", \"cnn.features.5.2.block.3.1.num_batches_tracked\", \"cnn.features.5.3.block.0.0.weight\", \"cnn.features.5.3.block.0.1.weight\", \"cnn.features.5.3.block.0.1.bias\", \"cnn.features.5.3.block.0.1.running_mean\", \"cnn.features.5.3.block.0.1.running_var\", \"cnn.features.5.3.block.0.1.num_batches_tracked\", \"cnn.features.5.3.block.1.0.weight\", \"cnn.features.5.3.block.1.1.weight\", \"cnn.features.5.3.block.1.1.bias\", \"cnn.features.5.3.block.1.1.running_mean\", \"cnn.features.5.3.block.1.1.running_var\", \"cnn.features.5.3.block.1.1.num_batches_tracked\", \"cnn.features.5.3.block.2.fc1.weight\", \"cnn.features.5.3.block.2.fc1.bias\", \"cnn.features.5.3.block.2.fc2.weight\", \"cnn.features.5.3.block.2.fc2.bias\", \"cnn.features.5.3.block.3.0.weight\", \"cnn.features.5.3.block.3.1.weight\", \"cnn.features.5.3.block.3.1.bias\", \"cnn.features.5.3.block.3.1.running_mean\", \"cnn.features.5.3.block.3.1.running_var\", \"cnn.features.5.3.block.3.1.num_batches_tracked\", \"cnn.features.6.0.block.0.0.weight\", \"cnn.features.6.0.block.0.1.weight\", \"cnn.features.6.0.block.0.1.bias\", \"cnn.features.6.0.block.0.1.running_mean\", \"cnn.features.6.0.block.0.1.running_var\", \"cnn.features.6.0.block.0.1.num_batches_tracked\", \"cnn.features.6.0.block.1.0.weight\", \"cnn.features.6.0.block.1.1.weight\", \"cnn.features.6.0.block.1.1.bias\", \"cnn.features.6.0.block.1.1.running_mean\", \"cnn.features.6.0.block.1.1.running_var\", \"cnn.features.6.0.block.1.1.num_batches_tracked\", \"cnn.features.6.0.block.2.fc1.weight\", \"cnn.features.6.0.block.2.fc1.bias\", \"cnn.features.6.0.block.2.fc2.weight\", \"cnn.features.6.0.block.2.fc2.bias\", \"cnn.features.6.0.block.3.0.weight\", \"cnn.features.6.0.block.3.1.weight\", \"cnn.features.6.0.block.3.1.bias\", \"cnn.features.6.0.block.3.1.running_mean\", \"cnn.features.6.0.block.3.1.running_var\", \"cnn.features.6.0.block.3.1.num_batches_tracked\", \"cnn.features.6.1.block.0.0.weight\", \"cnn.features.6.1.block.0.1.weight\", \"cnn.features.6.1.block.0.1.bias\", \"cnn.features.6.1.block.0.1.running_mean\", \"cnn.features.6.1.block.0.1.running_var\", \"cnn.features.6.1.block.0.1.num_batches_tracked\", \"cnn.features.6.1.block.1.0.weight\", \"cnn.features.6.1.block.1.1.weight\", \"cnn.features.6.1.block.1.1.bias\", \"cnn.features.6.1.block.1.1.running_mean\", \"cnn.features.6.1.block.1.1.running_var\", \"cnn.features.6.1.block.1.1.num_batches_tracked\", \"cnn.features.6.1.block.2.fc1.weight\", \"cnn.features.6.1.block.2.fc1.bias\", \"cnn.features.6.1.block.2.fc2.weight\", \"cnn.features.6.1.block.2.fc2.bias\", \"cnn.features.6.1.block.3.0.weight\", \"cnn.features.6.1.block.3.1.weight\", \"cnn.features.6.1.block.3.1.bias\", \"cnn.features.6.1.block.3.1.running_mean\", \"cnn.features.6.1.block.3.1.running_var\", \"cnn.features.6.1.block.3.1.num_batches_tracked\", \"cnn.features.6.2.block.0.0.weight\", \"cnn.features.6.2.block.0.1.weight\", \"cnn.features.6.2.block.0.1.bias\", \"cnn.features.6.2.block.0.1.running_mean\", \"cnn.features.6.2.block.0.1.running_var\", \"cnn.features.6.2.block.0.1.num_batches_tracked\", \"cnn.features.6.2.block.1.0.weight\", \"cnn.features.6.2.block.1.1.weight\", \"cnn.features.6.2.block.1.1.bias\", \"cnn.features.6.2.block.1.1.running_mean\", \"cnn.features.6.2.block.1.1.running_var\", \"cnn.features.6.2.block.1.1.num_batches_tracked\", \"cnn.features.6.2.block.2.fc1.weight\", \"cnn.features.6.2.block.2.fc1.bias\", \"cnn.features.6.2.block.2.fc2.weight\", \"cnn.features.6.2.block.2.fc2.bias\", \"cnn.features.6.2.block.3.0.weight\", \"cnn.features.6.2.block.3.1.weight\", \"cnn.features.6.2.block.3.1.bias\", \"cnn.features.6.2.block.3.1.running_mean\", \"cnn.features.6.2.block.3.1.running_var\", \"cnn.features.6.2.block.3.1.num_batches_tracked\", \"cnn.features.6.3.block.0.0.weight\", \"cnn.features.6.3.block.0.1.weight\", \"cnn.features.6.3.block.0.1.bias\", \"cnn.features.6.3.block.0.1.running_mean\", \"cnn.features.6.3.block.0.1.running_var\", \"cnn.features.6.3.block.0.1.num_batches_tracked\", \"cnn.features.6.3.block.1.0.weight\", \"cnn.features.6.3.block.1.1.weight\", \"cnn.features.6.3.block.1.1.bias\", \"cnn.features.6.3.block.1.1.running_mean\", \"cnn.features.6.3.block.1.1.running_var\", \"cnn.features.6.3.block.1.1.num_batches_tracked\", \"cnn.features.6.3.block.2.fc1.weight\", \"cnn.features.6.3.block.2.fc1.bias\", \"cnn.features.6.3.block.2.fc2.weight\", \"cnn.features.6.3.block.2.fc2.bias\", \"cnn.features.6.3.block.3.0.weight\", \"cnn.features.6.3.block.3.1.weight\", \"cnn.features.6.3.block.3.1.bias\", \"cnn.features.6.3.block.3.1.running_mean\", \"cnn.features.6.3.block.3.1.running_var\", \"cnn.features.6.3.block.3.1.num_batches_tracked\", \"cnn.features.6.4.block.0.0.weight\", \"cnn.features.6.4.block.0.1.weight\", \"cnn.features.6.4.block.0.1.bias\", \"cnn.features.6.4.block.0.1.running_mean\", \"cnn.features.6.4.block.0.1.running_var\", \"cnn.features.6.4.block.0.1.num_batches_tracked\", \"cnn.features.6.4.block.1.0.weight\", \"cnn.features.6.4.block.1.1.weight\", \"cnn.features.6.4.block.1.1.bias\", \"cnn.features.6.4.block.1.1.running_mean\", \"cnn.features.6.4.block.1.1.running_var\", \"cnn.features.6.4.block.1.1.num_batches_tracked\", \"cnn.features.6.4.block.2.fc1.weight\", \"cnn.features.6.4.block.2.fc1.bias\", \"cnn.features.6.4.block.2.fc2.weight\", \"cnn.features.6.4.block.2.fc2.bias\", \"cnn.features.6.4.block.3.0.weight\", \"cnn.features.6.4.block.3.1.weight\", \"cnn.features.6.4.block.3.1.bias\", \"cnn.features.6.4.block.3.1.running_mean\", \"cnn.features.6.4.block.3.1.running_var\", \"cnn.features.6.4.block.3.1.num_batches_tracked\", \"cnn.features.7.0.block.0.0.weight\", \"cnn.features.7.0.block.0.1.weight\", \"cnn.features.7.0.block.0.1.bias\", \"cnn.features.7.0.block.0.1.running_mean\", \"cnn.features.7.0.block.0.1.running_var\", \"cnn.features.7.0.block.0.1.num_batches_tracked\", \"cnn.features.7.0.block.1.0.weight\", \"cnn.features.7.0.block.1.1.weight\", \"cnn.features.7.0.block.1.1.bias\", \"cnn.features.7.0.block.1.1.running_mean\", \"cnn.features.7.0.block.1.1.running_var\", \"cnn.features.7.0.block.1.1.num_batches_tracked\", \"cnn.features.7.0.block.2.fc1.weight\", \"cnn.features.7.0.block.2.fc1.bias\", \"cnn.features.7.0.block.2.fc2.weight\", \"cnn.features.7.0.block.2.fc2.bias\", \"cnn.features.7.0.block.3.0.weight\", \"cnn.features.7.0.block.3.1.weight\", \"cnn.features.7.0.block.3.1.bias\", \"cnn.features.7.0.block.3.1.running_mean\", \"cnn.features.7.0.block.3.1.running_var\", \"cnn.features.7.0.block.3.1.num_batches_tracked\", \"cnn.features.7.1.block.0.0.weight\", \"cnn.features.7.1.block.0.1.weight\", \"cnn.features.7.1.block.0.1.bias\", \"cnn.features.7.1.block.0.1.running_mean\", \"cnn.features.7.1.block.0.1.running_var\", \"cnn.features.7.1.block.0.1.num_batches_tracked\", \"cnn.features.7.1.block.1.0.weight\", \"cnn.features.7.1.block.1.1.weight\", \"cnn.features.7.1.block.1.1.bias\", \"cnn.features.7.1.block.1.1.running_mean\", \"cnn.features.7.1.block.1.1.running_var\", \"cnn.features.7.1.block.1.1.num_batches_tracked\", \"cnn.features.7.1.block.2.fc1.weight\", \"cnn.features.7.1.block.2.fc1.bias\", \"cnn.features.7.1.block.2.fc2.weight\", \"cnn.features.7.1.block.2.fc2.bias\", \"cnn.features.7.1.block.3.0.weight\", \"cnn.features.7.1.block.3.1.weight\", \"cnn.features.7.1.block.3.1.bias\", \"cnn.features.7.1.block.3.1.running_mean\", \"cnn.features.7.1.block.3.1.running_var\", \"cnn.features.7.1.block.3.1.num_batches_tracked\", \"cnn.features.8.0.weight\", \"cnn.features.8.1.weight\", \"cnn.features.8.1.bias\", \"cnn.features.8.1.running_mean\", \"cnn.features.8.1.running_var\", \"cnn.features.8.1.num_batches_tracked\", \"cnn.classifier.1.weight\", \"cnn.classifier.1.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mUSE_DENOISING_AUTOENCODER:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCNN_ENCODER_SAVE_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m     evaluate_model(config\u001b[38;5;241m.\u001b[39mCNN_ENCODER_SAVE_PATH, noisy_val_loader, device)\n",
      "Cell \u001b[1;32mIn[13], line 26\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model_path, dataloader, device)\u001b[0m\n\u001b[0;32m     24\u001b[0m                 new_conv1\u001b[38;5;241m.\u001b[39mweight[:, i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m original_conv1\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39mfeatures[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m new_conv1\n\u001b[1;32m---> 26\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\dylan\\Desktop\\plant_disease_classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2189\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2184\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2185\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2186\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2190\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for EfficientNet:\n\tMissing key(s) in state_dict: \"features.0.0.weight\", \"features.0.1.weight\", \"features.0.1.bias\", \"features.0.1.running_mean\", \"features.0.1.running_var\", \"features.1.0.block.0.0.weight\", \"features.1.0.block.0.1.weight\", \"features.1.0.block.0.1.bias\", \"features.1.0.block.0.1.running_mean\", \"features.1.0.block.0.1.running_var\", \"features.1.0.block.1.fc1.weight\", \"features.1.0.block.1.fc1.bias\", \"features.1.0.block.1.fc2.weight\", \"features.1.0.block.1.fc2.bias\", \"features.1.0.block.2.0.weight\", \"features.1.0.block.2.1.weight\", \"features.1.0.block.2.1.bias\", \"features.1.0.block.2.1.running_mean\", \"features.1.0.block.2.1.running_var\", \"features.1.1.block.0.0.weight\", \"features.1.1.block.0.1.weight\", \"features.1.1.block.0.1.bias\", \"features.1.1.block.0.1.running_mean\", \"features.1.1.block.0.1.running_var\", \"features.1.1.block.1.fc1.weight\", \"features.1.1.block.1.fc1.bias\", \"features.1.1.block.1.fc2.weight\", \"features.1.1.block.1.fc2.bias\", \"features.1.1.block.2.0.weight\", \"features.1.1.block.2.1.weight\", \"features.1.1.block.2.1.bias\", \"features.1.1.block.2.1.running_mean\", \"features.1.1.block.2.1.running_var\", \"features.2.0.block.0.0.weight\", \"features.2.0.block.0.1.weight\", \"features.2.0.block.0.1.bias\", \"features.2.0.block.0.1.running_mean\", \"features.2.0.block.0.1.running_var\", \"features.2.0.block.1.0.weight\", \"features.2.0.block.1.1.weight\", \"features.2.0.block.1.1.bias\", \"features.2.0.block.1.1.running_mean\", \"features.2.0.block.1.1.running_var\", \"features.2.0.block.2.fc1.weight\", \"features.2.0.block.2.fc1.bias\", \"features.2.0.block.2.fc2.weight\", \"features.2.0.block.2.fc2.bias\", \"features.2.0.block.3.0.weight\", \"features.2.0.block.3.1.weight\", \"features.2.0.block.3.1.bias\", \"features.2.0.block.3.1.running_mean\", \"features.2.0.block.3.1.running_var\", \"features.2.1.block.0.0.weight\", \"features.2.1.block.0.1.weight\", \"features.2.1.block.0.1.bias\", \"features.2.1.block.0.1.running_mean\", \"features.2.1.block.0.1.running_var\", \"features.2.1.block.1.0.weight\", \"features.2.1.block.1.1.weight\", \"features.2.1.block.1.1.bias\", \"features.2.1.block.1.1.running_mean\", \"features.2.1.block.1.1.running_var\", \"features.2.1.block.2.fc1.weight\", \"features.2.1.block.2.fc1.bias\", \"features.2.1.block.2.fc2.weight\", \"features.2.1.block.2.fc2.bias\", \"features.2.1.block.3.0.weight\", \"features.2.1.block.3.1.weight\", \"features.2.1.block.3.1.bias\", \"features.2.1.block.3.1.running_mean\", \"features.2.1.block.3.1.running_var\", \"features.2.2.block.0.0.weight\", \"features.2.2.block.0.1.weight\", \"features.2.2.block.0.1.bias\", \"features.2.2.block.0.1.running_mean\", \"features.2.2.block.0.1.running_var\", \"features.2.2.block.1.0.weight\", \"features.2.2.block.1.1.weight\", \"features.2.2.block.1.1.bias\", \"features.2.2.block.1.1.running_mean\", \"features.2.2.block.1.1.running_var\", \"features.2.2.block.2.fc1.weight\", \"features.2.2.block.2.fc1.bias\", \"features.2.2.block.2.fc2.weight\", \"features.2.2.block.2.fc2.bias\", \"features.2.2.block.3.0.weight\", \"features.2.2.block.3.1.weight\", \"features.2.2.block.3.1.bias\", \"features.2.2.block.3.1.running_mean\", \"features.2.2.block.3.1.running_var\", \"features.3.0.block.0.0.weight\", \"features.3.0.block.0.1.weight\", \"features.3.0.block.0.1.bias\", \"features.3.0.block.0.1.running_mean\", \"features.3.0.block.0.1.running_var\", \"features.3.0.block.1.0.weight\", \"features.3.0.block.1.1.weight\", \"features.3.0.block.1.1.bias\", \"features.3.0.block.1.1.running_mean\", \"features.3.0.block.1.1.running_var\", \"features.3.0.block.2.fc1.weight\", \"features.3.0.block.2.fc1.bias\", \"features.3.0.block.2.fc2.weight\", \"features.3.0.block.2.fc2.bias\", \"features.3.0.block.3.0.weight\", \"features.3.0.block.3.1.weight\", \"features.3.0.block.3.1.bias\", \"features.3.0.block.3.1.running_mean\", \"features.3.0.block.3.1.running_var\", \"features.3.1.block.0.0.weight\", \"features.3.1.block.0.1.weight\", \"features.3.1.block.0.1.bias\", \"features.3.1.block.0.1.running_mean\", \"features.3.1.block.0.1.running_var\", \"features.3.1.block.1.0.weight\", \"features.3.1.block.1.1.weight\", \"features.3.1.block.1.1.bias\", \"features.3.1.block.1.1.running_mean\", \"features.3.1.block.1.1.running_var\", \"features.3.1.block.2.fc1.weight\", \"features.3.1.block.2.fc1.bias\", \"features.3.1.block.2.fc2.weight\", \"features.3.1.block.2.fc2.bias\", \"features.3.1.block.3.0.weight\", \"features.3.1.block.3.1.weight\", \"features.3.1.block.3.1.bias\", \"features.3.1.block.3.1.running_mean\", \"features.3.1.block.3.1.running_var\", \"features.3.2.block.0.0.weight\", \"features.3.2.block.0.1.weight\", \"features.3.2.block.0.1.bias\", \"features.3.2.block.0.1.running_mean\", \"features.3.2.block.0.1.running_var\", \"features.3.2.block.1.0.weight\", \"features.3.2.block.1.1.weight\", \"features.3.2.block.1.1.bias\", \"features.3.2.block.1.1.running_mean\", \"features.3.2.block.1.1.running_var\", \"features.3.2.block.2.fc1.weight\", \"features.3.2.block.2.fc1.bias\", \"features.3.2.block.2.fc2.weight\", \"features.3.2.block.2.fc2.bias\", \"features.3.2.block.3.0.weight\", \"features.3.2.block.3.1.weight\", \"features.3.2.block.3.1.bias\", \"features.3.2.block.3.1.running_mean\", \"features.3.2.block.3.1.running_var\", \"features.4.0.block.0.0.weight\", \"features.4.0.block.0.1.weight\", \"features.4.0.block.0.1.bias\", \"features.4.0.block.0.1.running_mean\", \"features.4.0.block.0.1.running_var\", \"features.4.0.block.1.0.weight\", \"features.4.0.block.1.1.weight\", \"features.4.0.block.1.1.bias\", \"features.4.0.block.1.1.running_mean\", \"features.4.0.block.1.1.running_var\", \"features.4.0.block.2.fc1.weight\", \"features.4.0.block.2.fc1.bias\", \"features.4.0.block.2.fc2.weight\", \"features.4.0.block.2.fc2.bias\", \"features.4.0.block.3.0.weight\", \"features.4.0.block.3.1.weight\", \"features.4.0.block.3.1.bias\", \"features.4.0.block.3.1.running_mean\", \"features.4.0.block.3.1.running_var\", \"features.4.1.block.0.0.weight\", \"features.4.1.block.0.1.weight\", \"features.4.1.block.0.1.bias\", \"features.4.1.block.0.1.running_mean\", \"features.4.1.block.0.1.running_var\", \"features.4.1.block.1.0.weight\", \"features.4.1.block.1.1.weight\", \"features.4.1.block.1.1.bias\", \"features.4.1.block.1.1.running_mean\", \"features.4.1.block.1.1.running_var\", \"features.4.1.block.2.fc1.weight\", \"features.4.1.block.2.fc1.bias\", \"features.4.1.block.2.fc2.weight\", \"features.4.1.block.2.fc2.bias\", \"features.4.1.block.3.0.weight\", \"features.4.1.block.3.1.weight\", \"features.4.1.block.3.1.bias\", \"features.4.1.block.3.1.running_mean\", \"features.4.1.block.3.1.running_var\", \"features.4.2.block.0.0.weight\", \"features.4.2.block.0.1.weight\", \"features.4.2.block.0.1.bias\", \"features.4.2.block.0.1.running_mean\", \"features.4.2.block.0.1.running_var\", \"features.4.2.block.1.0.weight\", \"features.4.2.block.1.1.weight\", \"features.4.2.block.1.1.bias\", \"features.4.2.block.1.1.running_mean\", \"features.4.2.block.1.1.running_var\", \"features.4.2.block.2.fc1.weight\", \"features.4.2.block.2.fc1.bias\", \"features.4.2.block.2.fc2.weight\", \"features.4.2.block.2.fc2.bias\", \"features.4.2.block.3.0.weight\", \"features.4.2.block.3.1.weight\", \"features.4.2.block.3.1.bias\", \"features.4.2.block.3.1.running_mean\", \"features.4.2.block.3.1.running_var\", \"features.4.3.block.0.0.weight\", \"features.4.3.block.0.1.weight\", \"features.4.3.block.0.1.bias\", \"features.4.3.block.0.1.running_mean\", \"features.4.3.block.0.1.running_var\", \"features.4.3.block.1.0.weight\", \"features.4.3.block.1.1.weight\", \"features.4.3.block.1.1.bias\", \"features.4.3.block.1.1.running_mean\", \"features.4.3.block.1.1.running_var\", \"features.4.3.block.2.fc1.weight\", \"features.4.3.block.2.fc1.bias\", \"features.4.3.block.2.fc2.weight\", \"features.4.3.block.2.fc2.bias\", \"features.4.3.block.3.0.weight\", \"features.4.3.block.3.1.weight\", \"features.4.3.block.3.1.bias\", \"features.4.3.block.3.1.running_mean\", \"features.4.3.block.3.1.running_var\", \"features.5.0.block.0.0.weight\", \"features.5.0.block.0.1.weight\", \"features.5.0.block.0.1.bias\", \"features.5.0.block.0.1.running_mean\", \"features.5.0.block.0.1.running_var\", \"features.5.0.block.1.0.weight\", \"features.5.0.block.1.1.weight\", \"features.5.0.block.1.1.bias\", \"features.5.0.block.1.1.running_mean\", \"features.5.0.block.1.1.running_var\", \"features.5.0.block.2.fc1.weight\", \"features.5.0.block.2.fc1.bias\", \"features.5.0.block.2.fc2.weight\", \"features.5.0.block.2.fc2.bias\", \"features.5.0.block.3.0.weight\", \"features.5.0.block.3.1.weight\", \"features.5.0.block.3.1.bias\", \"features.5.0.block.3.1.running_mean\", \"features.5.0.block.3.1.running_var\", \"features.5.1.block.0.0.weight\", \"features.5.1.block.0.1.weight\", \"features.5.1.block.0.1.bias\", \"features.5.1.block.0.1.running_mean\", \"features.5.1.block.0.1.running_var\", \"features.5.1.block.1.0.weight\", \"features.5.1.block.1.1.weight\", \"features.5.1.block.1.1.bias\", \"features.5.1.block.1.1.running_mean\", \"features.5.1.block.1.1.running_var\", \"features.5.1.block.2.fc1.weight\", \"features.5.1.block.2.fc1.bias\", \"features.5.1.block.2.fc2.weight\", \"features.5.1.block.2.fc2.bias\", \"features.5.1.block.3.0.weight\", \"features.5.1.block.3.1.weight\", \"features.5.1.block.3.1.bias\", \"features.5.1.block.3.1.running_mean\", \"features.5.1.block.3.1.running_var\", \"features.5.2.block.0.0.weight\", \"features.5.2.block.0.1.weight\", \"features.5.2.block.0.1.bias\", \"features.5.2.block.0.1.running_mean\", \"features.5.2.block.0.1.running_var\", \"features.5.2.block.1.0.weight\", \"features.5.2.block.1.1.weight\", \"features.5.2.block.1.1.bias\", \"features.5.2.block.1.1.running_mean\", \"features.5.2.block.1.1.running_var\", \"features.5.2.block.2.fc1.weight\", \"features.5.2.block.2.fc1.bias\", \"features.5.2.block.2.fc2.weight\", \"features.5.2.block.2.fc2.bias\", \"features.5.2.block.3.0.weight\", \"features.5.2.block.3.1.weight\", \"features.5.2.block.3.1.bias\", \"features.5.2.block.3.1.running_mean\", \"features.5.2.block.3.1.running_var\", \"features.5.3.block.0.0.weight\", \"features.5.3.block.0.1.weight\", \"features.5.3.block.0.1.bias\", \"features.5.3.block.0.1.running_mean\", \"features.5.3.block.0.1.running_var\", \"features.5.3.block.1.0.weight\", \"features.5.3.block.1.1.weight\", \"features.5.3.block.1.1.bias\", \"features.5.3.block.1.1.running_mean\", \"features.5.3.block.1.1.running_var\", \"features.5.3.block.2.fc1.weight\", \"features.5.3.block.2.fc1.bias\", \"features.5.3.block.2.fc2.weight\", \"features.5.3.block.2.fc2.bias\", \"features.5.3.block.3.0.weight\", \"features.5.3.block.3.1.weight\", \"features.5.3.block.3.1.bias\", \"features.5.3.block.3.1.running_mean\", \"features.5.3.block.3.1.running_var\", \"features.6.0.block.0.0.weight\", \"features.6.0.block.0.1.weight\", \"features.6.0.block.0.1.bias\", \"features.6.0.block.0.1.running_mean\", \"features.6.0.block.0.1.running_var\", \"features.6.0.block.1.0.weight\", \"features.6.0.block.1.1.weight\", \"features.6.0.block.1.1.bias\", \"features.6.0.block.1.1.running_mean\", \"features.6.0.block.1.1.running_var\", \"features.6.0.block.2.fc1.weight\", \"features.6.0.block.2.fc1.bias\", \"features.6.0.block.2.fc2.weight\", \"features.6.0.block.2.fc2.bias\", \"features.6.0.block.3.0.weight\", \"features.6.0.block.3.1.weight\", \"features.6.0.block.3.1.bias\", \"features.6.0.block.3.1.running_mean\", \"features.6.0.block.3.1.running_var\", \"features.6.1.block.0.0.weight\", \"features.6.1.block.0.1.weight\", \"features.6.1.block.0.1.bias\", \"features.6.1.block.0.1.running_mean\", \"features.6.1.block.0.1.running_var\", \"features.6.1.block.1.0.weight\", \"features.6.1.block.1.1.weight\", \"features.6.1.block.1.1.bias\", \"features.6.1.block.1.1.running_mean\", \"features.6.1.block.1.1.running_var\", \"features.6.1.block.2.fc1.weight\", \"features.6.1.block.2.fc1.bias\", \"features.6.1.block.2.fc2.weight\", \"features.6.1.block.2.fc2.bias\", \"features.6.1.block.3.0.weight\", \"features.6.1.block.3.1.weight\", \"features.6.1.block.3.1.bias\", \"features.6.1.block.3.1.running_mean\", \"features.6.1.block.3.1.running_var\", \"features.6.2.block.0.0.weight\", \"features.6.2.block.0.1.weight\", \"features.6.2.block.0.1.bias\", \"features.6.2.block.0.1.running_mean\", \"features.6.2.block.0.1.running_var\", \"features.6.2.block.1.0.weight\", \"features.6.2.block.1.1.weight\", \"features.6.2.block.1.1.bias\", \"features.6.2.block.1.1.running_mean\", \"features.6.2.block.1.1.running_var\", \"features.6.2.block.2.fc1.weight\", \"features.6.2.block.2.fc1.bias\", \"features.6.2.block.2.fc2.weight\", \"features.6.2.block.2.fc2.bias\", \"features.6.2.block.3.0.weight\", \"features.6.2.block.3.1.weight\", \"features.6.2.block.3.1.bias\", \"features.6.2.block.3.1.running_mean\", \"features.6.2.block.3.1.running_var\", \"features.6.3.block.0.0.weight\", \"features.6.3.block.0.1.weight\", \"features.6.3.block.0.1.bias\", \"features.6.3.block.0.1.running_mean\", \"features.6.3.block.0.1.running_var\", \"features.6.3.block.1.0.weight\", \"features.6.3.block.1.1.weight\", \"features.6.3.block.1.1.bias\", \"features.6.3.block.1.1.running_mean\", \"features.6.3.block.1.1.running_var\", \"features.6.3.block.2.fc1.weight\", \"features.6.3.block.2.fc1.bias\", \"features.6.3.block.2.fc2.weight\", \"features.6.3.block.2.fc2.bias\", \"features.6.3.block.3.0.weight\", \"features.6.3.block.3.1.weight\", \"features.6.3.block.3.1.bias\", \"features.6.3.block.3.1.running_mean\", \"features.6.3.block.3.1.running_var\", \"features.6.4.block.0.0.weight\", \"features.6.4.block.0.1.weight\", \"features.6.4.block.0.1.bias\", \"features.6.4.block.0.1.running_mean\", \"features.6.4.block.0.1.running_var\", \"features.6.4.block.1.0.weight\", \"features.6.4.block.1.1.weight\", \"features.6.4.block.1.1.bias\", \"features.6.4.block.1.1.running_mean\", \"features.6.4.block.1.1.running_var\", \"features.6.4.block.2.fc1.weight\", \"features.6.4.block.2.fc1.bias\", \"features.6.4.block.2.fc2.weight\", \"features.6.4.block.2.fc2.bias\", \"features.6.4.block.3.0.weight\", \"features.6.4.block.3.1.weight\", \"features.6.4.block.3.1.bias\", \"features.6.4.block.3.1.running_mean\", \"features.6.4.block.3.1.running_var\", \"features.7.0.block.0.0.weight\", \"features.7.0.block.0.1.weight\", \"features.7.0.block.0.1.bias\", \"features.7.0.block.0.1.running_mean\", \"features.7.0.block.0.1.running_var\", \"features.7.0.block.1.0.weight\", \"features.7.0.block.1.1.weight\", \"features.7.0.block.1.1.bias\", \"features.7.0.block.1.1.running_mean\", \"features.7.0.block.1.1.running_var\", \"features.7.0.block.2.fc1.weight\", \"features.7.0.block.2.fc1.bias\", \"features.7.0.block.2.fc2.weight\", \"features.7.0.block.2.fc2.bias\", \"features.7.0.block.3.0.weight\", \"features.7.0.block.3.1.weight\", \"features.7.0.block.3.1.bias\", \"features.7.0.block.3.1.running_mean\", \"features.7.0.block.3.1.running_var\", \"features.7.1.block.0.0.weight\", \"features.7.1.block.0.1.weight\", \"features.7.1.block.0.1.bias\", \"features.7.1.block.0.1.running_mean\", \"features.7.1.block.0.1.running_var\", \"features.7.1.block.1.0.weight\", \"features.7.1.block.1.1.weight\", \"features.7.1.block.1.1.bias\", \"features.7.1.block.1.1.running_mean\", \"features.7.1.block.1.1.running_var\", \"features.7.1.block.2.fc1.weight\", \"features.7.1.block.2.fc1.bias\", \"features.7.1.block.2.fc2.weight\", \"features.7.1.block.2.fc2.bias\", \"features.7.1.block.3.0.weight\", \"features.7.1.block.3.1.weight\", \"features.7.1.block.3.1.bias\", \"features.7.1.block.3.1.running_mean\", \"features.7.1.block.3.1.running_var\", \"features.8.0.weight\", \"features.8.1.weight\", \"features.8.1.bias\", \"features.8.1.running_mean\", \"features.8.1.running_var\", \"classifier.1.weight\", \"classifier.1.bias\". \n\tUnexpected key(s) in state_dict: \"encoder.inc.conv.conv.0.weight\", \"encoder.inc.conv.conv.0.bias\", \"encoder.inc.conv.conv.1.weight\", \"encoder.inc.conv.conv.1.bias\", \"encoder.inc.conv.conv.1.running_mean\", \"encoder.inc.conv.conv.1.running_var\", \"encoder.inc.conv.conv.1.num_batches_tracked\", \"encoder.inc.conv.conv.3.weight\", \"encoder.inc.conv.conv.3.bias\", \"encoder.inc.conv.conv.4.weight\", \"encoder.inc.conv.conv.4.bias\", \"encoder.inc.conv.conv.4.running_mean\", \"encoder.inc.conv.conv.4.running_var\", \"encoder.inc.conv.conv.4.num_batches_tracked\", \"encoder.down1.mpconv.1.conv.0.weight\", \"encoder.down1.mpconv.1.conv.0.bias\", \"encoder.down1.mpconv.1.conv.1.weight\", \"encoder.down1.mpconv.1.conv.1.bias\", \"encoder.down1.mpconv.1.conv.1.running_mean\", \"encoder.down1.mpconv.1.conv.1.running_var\", \"encoder.down1.mpconv.1.conv.1.num_batches_tracked\", \"encoder.down1.mpconv.1.conv.3.weight\", \"encoder.down1.mpconv.1.conv.3.bias\", \"encoder.down1.mpconv.1.conv.4.weight\", \"encoder.down1.mpconv.1.conv.4.bias\", \"encoder.down1.mpconv.1.conv.4.running_mean\", \"encoder.down1.mpconv.1.conv.4.running_var\", \"encoder.down1.mpconv.1.conv.4.num_batches_tracked\", \"encoder.down2.mpconv.1.conv.0.weight\", \"encoder.down2.mpconv.1.conv.0.bias\", \"encoder.down2.mpconv.1.conv.1.weight\", \"encoder.down2.mpconv.1.conv.1.bias\", \"encoder.down2.mpconv.1.conv.1.running_mean\", \"encoder.down2.mpconv.1.conv.1.running_var\", \"encoder.down2.mpconv.1.conv.1.num_batches_tracked\", \"encoder.down2.mpconv.1.conv.3.weight\", \"encoder.down2.mpconv.1.conv.3.bias\", \"encoder.down2.mpconv.1.conv.4.weight\", \"encoder.down2.mpconv.1.conv.4.bias\", \"encoder.down2.mpconv.1.conv.4.running_mean\", \"encoder.down2.mpconv.1.conv.4.running_var\", \"encoder.down2.mpconv.1.conv.4.num_batches_tracked\", \"encoder.down3.mpconv.1.conv.0.weight\", \"encoder.down3.mpconv.1.conv.0.bias\", \"encoder.down3.mpconv.1.conv.1.weight\", \"encoder.down3.mpconv.1.conv.1.bias\", \"encoder.down3.mpconv.1.conv.1.running_mean\", \"encoder.down3.mpconv.1.conv.1.running_var\", \"encoder.down3.mpconv.1.conv.1.num_batches_tracked\", \"encoder.down3.mpconv.1.conv.3.weight\", \"encoder.down3.mpconv.1.conv.3.bias\", \"encoder.down3.mpconv.1.conv.4.weight\", \"encoder.down3.mpconv.1.conv.4.bias\", \"encoder.down3.mpconv.1.conv.4.running_mean\", \"encoder.down3.mpconv.1.conv.4.running_var\", \"encoder.down3.mpconv.1.conv.4.num_batches_tracked\", \"encoder.down4.mpconv.1.conv.0.weight\", \"encoder.down4.mpconv.1.conv.0.bias\", \"encoder.down4.mpconv.1.conv.1.weight\", \"encoder.down4.mpconv.1.conv.1.bias\", \"encoder.down4.mpconv.1.conv.1.running_mean\", \"encoder.down4.mpconv.1.conv.1.running_var\", \"encoder.down4.mpconv.1.conv.1.num_batches_tracked\", \"encoder.down4.mpconv.1.conv.3.weight\", \"encoder.down4.mpconv.1.conv.3.bias\", \"encoder.down4.mpconv.1.conv.4.weight\", \"encoder.down4.mpconv.1.conv.4.bias\", \"encoder.down4.mpconv.1.conv.4.running_mean\", \"encoder.down4.mpconv.1.conv.4.running_var\", \"encoder.down4.mpconv.1.conv.4.num_batches_tracked\", \"cnn.features.0.0.weight\", \"cnn.features.0.1.weight\", \"cnn.features.0.1.bias\", \"cnn.features.0.1.running_mean\", \"cnn.features.0.1.running_var\", \"cnn.features.0.1.num_batches_tracked\", \"cnn.features.1.0.block.0.0.weight\", \"cnn.features.1.0.block.0.1.weight\", \"cnn.features.1.0.block.0.1.bias\", \"cnn.features.1.0.block.0.1.running_mean\", \"cnn.features.1.0.block.0.1.running_var\", \"cnn.features.1.0.block.0.1.num_batches_tracked\", \"cnn.features.1.0.block.1.fc1.weight\", \"cnn.features.1.0.block.1.fc1.bias\", \"cnn.features.1.0.block.1.fc2.weight\", \"cnn.features.1.0.block.1.fc2.bias\", \"cnn.features.1.0.block.2.0.weight\", \"cnn.features.1.0.block.2.1.weight\", \"cnn.features.1.0.block.2.1.bias\", \"cnn.features.1.0.block.2.1.running_mean\", \"cnn.features.1.0.block.2.1.running_var\", \"cnn.features.1.0.block.2.1.num_batches_tracked\", \"cnn.features.1.1.block.0.0.weight\", \"cnn.features.1.1.block.0.1.weight\", \"cnn.features.1.1.block.0.1.bias\", \"cnn.features.1.1.block.0.1.running_mean\", \"cnn.features.1.1.block.0.1.running_var\", \"cnn.features.1.1.block.0.1.num_batches_tracked\", \"cnn.features.1.1.block.1.fc1.weight\", \"cnn.features.1.1.block.1.fc1.bias\", \"cnn.features.1.1.block.1.fc2.weight\", \"cnn.features.1.1.block.1.fc2.bias\", \"cnn.features.1.1.block.2.0.weight\", \"cnn.features.1.1.block.2.1.weight\", \"cnn.features.1.1.block.2.1.bias\", \"cnn.features.1.1.block.2.1.running_mean\", \"cnn.features.1.1.block.2.1.running_var\", \"cnn.features.1.1.block.2.1.num_batches_tracked\", \"cnn.features.2.0.block.0.0.weight\", \"cnn.features.2.0.block.0.1.weight\", \"cnn.features.2.0.block.0.1.bias\", \"cnn.features.2.0.block.0.1.running_mean\", \"cnn.features.2.0.block.0.1.running_var\", \"cnn.features.2.0.block.0.1.num_batches_tracked\", \"cnn.features.2.0.block.1.0.weight\", \"cnn.features.2.0.block.1.1.weight\", \"cnn.features.2.0.block.1.1.bias\", \"cnn.features.2.0.block.1.1.running_mean\", \"cnn.features.2.0.block.1.1.running_var\", \"cnn.features.2.0.block.1.1.num_batches_tracked\", \"cnn.features.2.0.block.2.fc1.weight\", \"cnn.features.2.0.block.2.fc1.bias\", \"cnn.features.2.0.block.2.fc2.weight\", \"cnn.features.2.0.block.2.fc2.bias\", \"cnn.features.2.0.block.3.0.weight\", \"cnn.features.2.0.block.3.1.weight\", \"cnn.features.2.0.block.3.1.bias\", \"cnn.features.2.0.block.3.1.running_mean\", \"cnn.features.2.0.block.3.1.running_var\", \"cnn.features.2.0.block.3.1.num_batches_tracked\", \"cnn.features.2.1.block.0.0.weight\", \"cnn.features.2.1.block.0.1.weight\", \"cnn.features.2.1.block.0.1.bias\", \"cnn.features.2.1.block.0.1.running_mean\", \"cnn.features.2.1.block.0.1.running_var\", \"cnn.features.2.1.block.0.1.num_batches_tracked\", \"cnn.features.2.1.block.1.0.weight\", \"cnn.features.2.1.block.1.1.weight\", \"cnn.features.2.1.block.1.1.bias\", \"cnn.features.2.1.block.1.1.running_mean\", \"cnn.features.2.1.block.1.1.running_var\", \"cnn.features.2.1.block.1.1.num_batches_tracked\", \"cnn.features.2.1.block.2.fc1.weight\", \"cnn.features.2.1.block.2.fc1.bias\", \"cnn.features.2.1.block.2.fc2.weight\", \"cnn.features.2.1.block.2.fc2.bias\", \"cnn.features.2.1.block.3.0.weight\", \"cnn.features.2.1.block.3.1.weight\", \"cnn.features.2.1.block.3.1.bias\", \"cnn.features.2.1.block.3.1.running_mean\", \"cnn.features.2.1.block.3.1.running_var\", \"cnn.features.2.1.block.3.1.num_batches_tracked\", \"cnn.features.2.2.block.0.0.weight\", \"cnn.features.2.2.block.0.1.weight\", \"cnn.features.2.2.block.0.1.bias\", \"cnn.features.2.2.block.0.1.running_mean\", \"cnn.features.2.2.block.0.1.running_var\", \"cnn.features.2.2.block.0.1.num_batches_tracked\", \"cnn.features.2.2.block.1.0.weight\", \"cnn.features.2.2.block.1.1.weight\", \"cnn.features.2.2.block.1.1.bias\", \"cnn.features.2.2.block.1.1.running_mean\", \"cnn.features.2.2.block.1.1.running_var\", \"cnn.features.2.2.block.1.1.num_batches_tracked\", \"cnn.features.2.2.block.2.fc1.weight\", \"cnn.features.2.2.block.2.fc1.bias\", \"cnn.features.2.2.block.2.fc2.weight\", \"cnn.features.2.2.block.2.fc2.bias\", \"cnn.features.2.2.block.3.0.weight\", \"cnn.features.2.2.block.3.1.weight\", \"cnn.features.2.2.block.3.1.bias\", \"cnn.features.2.2.block.3.1.running_mean\", \"cnn.features.2.2.block.3.1.running_var\", \"cnn.features.2.2.block.3.1.num_batches_tracked\", \"cnn.features.3.0.block.0.0.weight\", \"cnn.features.3.0.block.0.1.weight\", \"cnn.features.3.0.block.0.1.bias\", \"cnn.features.3.0.block.0.1.running_mean\", \"cnn.features.3.0.block.0.1.running_var\", \"cnn.features.3.0.block.0.1.num_batches_tracked\", \"cnn.features.3.0.block.1.0.weight\", \"cnn.features.3.0.block.1.1.weight\", \"cnn.features.3.0.block.1.1.bias\", \"cnn.features.3.0.block.1.1.running_mean\", \"cnn.features.3.0.block.1.1.running_var\", \"cnn.features.3.0.block.1.1.num_batches_tracked\", \"cnn.features.3.0.block.2.fc1.weight\", \"cnn.features.3.0.block.2.fc1.bias\", \"cnn.features.3.0.block.2.fc2.weight\", \"cnn.features.3.0.block.2.fc2.bias\", \"cnn.features.3.0.block.3.0.weight\", \"cnn.features.3.0.block.3.1.weight\", \"cnn.features.3.0.block.3.1.bias\", \"cnn.features.3.0.block.3.1.running_mean\", \"cnn.features.3.0.block.3.1.running_var\", \"cnn.features.3.0.block.3.1.num_batches_tracked\", \"cnn.features.3.1.block.0.0.weight\", \"cnn.features.3.1.block.0.1.weight\", \"cnn.features.3.1.block.0.1.bias\", \"cnn.features.3.1.block.0.1.running_mean\", \"cnn.features.3.1.block.0.1.running_var\", \"cnn.features.3.1.block.0.1.num_batches_tracked\", \"cnn.features.3.1.block.1.0.weight\", \"cnn.features.3.1.block.1.1.weight\", \"cnn.features.3.1.block.1.1.bias\", \"cnn.features.3.1.block.1.1.running_mean\", \"cnn.features.3.1.block.1.1.running_var\", \"cnn.features.3.1.block.1.1.num_batches_tracked\", \"cnn.features.3.1.block.2.fc1.weight\", \"cnn.features.3.1.block.2.fc1.bias\", \"cnn.features.3.1.block.2.fc2.weight\", \"cnn.features.3.1.block.2.fc2.bias\", \"cnn.features.3.1.block.3.0.weight\", \"cnn.features.3.1.block.3.1.weight\", \"cnn.features.3.1.block.3.1.bias\", \"cnn.features.3.1.block.3.1.running_mean\", \"cnn.features.3.1.block.3.1.running_var\", \"cnn.features.3.1.block.3.1.num_batches_tracked\", \"cnn.features.3.2.block.0.0.weight\", \"cnn.features.3.2.block.0.1.weight\", \"cnn.features.3.2.block.0.1.bias\", \"cnn.features.3.2.block.0.1.running_mean\", \"cnn.features.3.2.block.0.1.running_var\", \"cnn.features.3.2.block.0.1.num_batches_tracked\", \"cnn.features.3.2.block.1.0.weight\", \"cnn.features.3.2.block.1.1.weight\", \"cnn.features.3.2.block.1.1.bias\", \"cnn.features.3.2.block.1.1.running_mean\", \"cnn.features.3.2.block.1.1.running_var\", \"cnn.features.3.2.block.1.1.num_batches_tracked\", \"cnn.features.3.2.block.2.fc1.weight\", \"cnn.features.3.2.block.2.fc1.bias\", \"cnn.features.3.2.block.2.fc2.weight\", \"cnn.features.3.2.block.2.fc2.bias\", \"cnn.features.3.2.block.3.0.weight\", \"cnn.features.3.2.block.3.1.weight\", \"cnn.features.3.2.block.3.1.bias\", \"cnn.features.3.2.block.3.1.running_mean\", \"cnn.features.3.2.block.3.1.running_var\", \"cnn.features.3.2.block.3.1.num_batches_tracked\", \"cnn.features.4.0.block.0.0.weight\", \"cnn.features.4.0.block.0.1.weight\", \"cnn.features.4.0.block.0.1.bias\", \"cnn.features.4.0.block.0.1.running_mean\", \"cnn.features.4.0.block.0.1.running_var\", \"cnn.features.4.0.block.0.1.num_batches_tracked\", \"cnn.features.4.0.block.1.0.weight\", \"cnn.features.4.0.block.1.1.weight\", \"cnn.features.4.0.block.1.1.bias\", \"cnn.features.4.0.block.1.1.running_mean\", \"cnn.features.4.0.block.1.1.running_var\", \"cnn.features.4.0.block.1.1.num_batches_tracked\", \"cnn.features.4.0.block.2.fc1.weight\", \"cnn.features.4.0.block.2.fc1.bias\", \"cnn.features.4.0.block.2.fc2.weight\", \"cnn.features.4.0.block.2.fc2.bias\", \"cnn.features.4.0.block.3.0.weight\", \"cnn.features.4.0.block.3.1.weight\", \"cnn.features.4.0.block.3.1.bias\", \"cnn.features.4.0.block.3.1.running_mean\", \"cnn.features.4.0.block.3.1.running_var\", \"cnn.features.4.0.block.3.1.num_batches_tracked\", \"cnn.features.4.1.block.0.0.weight\", \"cnn.features.4.1.block.0.1.weight\", \"cnn.features.4.1.block.0.1.bias\", \"cnn.features.4.1.block.0.1.running_mean\", \"cnn.features.4.1.block.0.1.running_var\", \"cnn.features.4.1.block.0.1.num_batches_tracked\", \"cnn.features.4.1.block.1.0.weight\", \"cnn.features.4.1.block.1.1.weight\", \"cnn.features.4.1.block.1.1.bias\", \"cnn.features.4.1.block.1.1.running_mean\", \"cnn.features.4.1.block.1.1.running_var\", \"cnn.features.4.1.block.1.1.num_batches_tracked\", \"cnn.features.4.1.block.2.fc1.weight\", \"cnn.features.4.1.block.2.fc1.bias\", \"cnn.features.4.1.block.2.fc2.weight\", \"cnn.features.4.1.block.2.fc2.bias\", \"cnn.features.4.1.block.3.0.weight\", \"cnn.features.4.1.block.3.1.weight\", \"cnn.features.4.1.block.3.1.bias\", \"cnn.features.4.1.block.3.1.running_mean\", \"cnn.features.4.1.block.3.1.running_var\", \"cnn.features.4.1.block.3.1.num_batches_tracked\", \"cnn.features.4.2.block.0.0.weight\", \"cnn.features.4.2.block.0.1.weight\", \"cnn.features.4.2.block.0.1.bias\", \"cnn.features.4.2.block.0.1.running_mean\", \"cnn.features.4.2.block.0.1.running_var\", \"cnn.features.4.2.block.0.1.num_batches_tracked\", \"cnn.features.4.2.block.1.0.weight\", \"cnn.features.4.2.block.1.1.weight\", \"cnn.features.4.2.block.1.1.bias\", \"cnn.features.4.2.block.1.1.running_mean\", \"cnn.features.4.2.block.1.1.running_var\", \"cnn.features.4.2.block.1.1.num_batches_tracked\", \"cnn.features.4.2.block.2.fc1.weight\", \"cnn.features.4.2.block.2.fc1.bias\", \"cnn.features.4.2.block.2.fc2.weight\", \"cnn.features.4.2.block.2.fc2.bias\", \"cnn.features.4.2.block.3.0.weight\", \"cnn.features.4.2.block.3.1.weight\", \"cnn.features.4.2.block.3.1.bias\", \"cnn.features.4.2.block.3.1.running_mean\", \"cnn.features.4.2.block.3.1.running_var\", \"cnn.features.4.2.block.3.1.num_batches_tracked\", \"cnn.features.4.3.block.0.0.weight\", \"cnn.features.4.3.block.0.1.weight\", \"cnn.features.4.3.block.0.1.bias\", \"cnn.features.4.3.block.0.1.running_mean\", \"cnn.features.4.3.block.0.1.running_var\", \"cnn.features.4.3.block.0.1.num_batches_tracked\", \"cnn.features.4.3.block.1.0.weight\", \"cnn.features.4.3.block.1.1.weight\", \"cnn.features.4.3.block.1.1.bias\", \"cnn.features.4.3.block.1.1.running_mean\", \"cnn.features.4.3.block.1.1.running_var\", \"cnn.features.4.3.block.1.1.num_batches_tracked\", \"cnn.features.4.3.block.2.fc1.weight\", \"cnn.features.4.3.block.2.fc1.bias\", \"cnn.features.4.3.block.2.fc2.weight\", \"cnn.features.4.3.block.2.fc2.bias\", \"cnn.features.4.3.block.3.0.weight\", \"cnn.features.4.3.block.3.1.weight\", \"cnn.features.4.3.block.3.1.bias\", \"cnn.features.4.3.block.3.1.running_mean\", \"cnn.features.4.3.block.3.1.running_var\", \"cnn.features.4.3.block.3.1.num_batches_tracked\", \"cnn.features.5.0.block.0.0.weight\", \"cnn.features.5.0.block.0.1.weight\", \"cnn.features.5.0.block.0.1.bias\", \"cnn.features.5.0.block.0.1.running_mean\", \"cnn.features.5.0.block.0.1.running_var\", \"cnn.features.5.0.block.0.1.num_batches_tracked\", \"cnn.features.5.0.block.1.0.weight\", \"cnn.features.5.0.block.1.1.weight\", \"cnn.features.5.0.block.1.1.bias\", \"cnn.features.5.0.block.1.1.running_mean\", \"cnn.features.5.0.block.1.1.running_var\", \"cnn.features.5.0.block.1.1.num_batches_tracked\", \"cnn.features.5.0.block.2.fc1.weight\", \"cnn.features.5.0.block.2.fc1.bias\", \"cnn.features.5.0.block.2.fc2.weight\", \"cnn.features.5.0.block.2.fc2.bias\", \"cnn.features.5.0.block.3.0.weight\", \"cnn.features.5.0.block.3.1.weight\", \"cnn.features.5.0.block.3.1.bias\", \"cnn.features.5.0.block.3.1.running_mean\", \"cnn.features.5.0.block.3.1.running_var\", \"cnn.features.5.0.block.3.1.num_batches_tracked\", \"cnn.features.5.1.block.0.0.weight\", \"cnn.features.5.1.block.0.1.weight\", \"cnn.features.5.1.block.0.1.bias\", \"cnn.features.5.1.block.0.1.running_mean\", \"cnn.features.5.1.block.0.1.running_var\", \"cnn.features.5.1.block.0.1.num_batches_tracked\", \"cnn.features.5.1.block.1.0.weight\", \"cnn.features.5.1.block.1.1.weight\", \"cnn.features.5.1.block.1.1.bias\", \"cnn.features.5.1.block.1.1.running_mean\", \"cnn.features.5.1.block.1.1.running_var\", \"cnn.features.5.1.block.1.1.num_batches_tracked\", \"cnn.features.5.1.block.2.fc1.weight\", \"cnn.features.5.1.block.2.fc1.bias\", \"cnn.features.5.1.block.2.fc2.weight\", \"cnn.features.5.1.block.2.fc2.bias\", \"cnn.features.5.1.block.3.0.weight\", \"cnn.features.5.1.block.3.1.weight\", \"cnn.features.5.1.block.3.1.bias\", \"cnn.features.5.1.block.3.1.running_mean\", \"cnn.features.5.1.block.3.1.running_var\", \"cnn.features.5.1.block.3.1.num_batches_tracked\", \"cnn.features.5.2.block.0.0.weight\", \"cnn.features.5.2.block.0.1.weight\", \"cnn.features.5.2.block.0.1.bias\", \"cnn.features.5.2.block.0.1.running_mean\", \"cnn.features.5.2.block.0.1.running_var\", \"cnn.features.5.2.block.0.1.num_batches_tracked\", \"cnn.features.5.2.block.1.0.weight\", \"cnn.features.5.2.block.1.1.weight\", \"cnn.features.5.2.block.1.1.bias\", \"cnn.features.5.2.block.1.1.running_mean\", \"cnn.features.5.2.block.1.1.running_var\", \"cnn.features.5.2.block.1.1.num_batches_tracked\", \"cnn.features.5.2.block.2.fc1.weight\", \"cnn.features.5.2.block.2.fc1.bias\", \"cnn.features.5.2.block.2.fc2.weight\", \"cnn.features.5.2.block.2.fc2.bias\", \"cnn.features.5.2.block.3.0.weight\", \"cnn.features.5.2.block.3.1.weight\", \"cnn.features.5.2.block.3.1.bias\", \"cnn.features.5.2.block.3.1.running_mean\", \"cnn.features.5.2.block.3.1.running_var\", \"cnn.features.5.2.block.3.1.num_batches_tracked\", \"cnn.features.5.3.block.0.0.weight\", \"cnn.features.5.3.block.0.1.weight\", \"cnn.features.5.3.block.0.1.bias\", \"cnn.features.5.3.block.0.1.running_mean\", \"cnn.features.5.3.block.0.1.running_var\", \"cnn.features.5.3.block.0.1.num_batches_tracked\", \"cnn.features.5.3.block.1.0.weight\", \"cnn.features.5.3.block.1.1.weight\", \"cnn.features.5.3.block.1.1.bias\", \"cnn.features.5.3.block.1.1.running_mean\", \"cnn.features.5.3.block.1.1.running_var\", \"cnn.features.5.3.block.1.1.num_batches_tracked\", \"cnn.features.5.3.block.2.fc1.weight\", \"cnn.features.5.3.block.2.fc1.bias\", \"cnn.features.5.3.block.2.fc2.weight\", \"cnn.features.5.3.block.2.fc2.bias\", \"cnn.features.5.3.block.3.0.weight\", \"cnn.features.5.3.block.3.1.weight\", \"cnn.features.5.3.block.3.1.bias\", \"cnn.features.5.3.block.3.1.running_mean\", \"cnn.features.5.3.block.3.1.running_var\", \"cnn.features.5.3.block.3.1.num_batches_tracked\", \"cnn.features.6.0.block.0.0.weight\", \"cnn.features.6.0.block.0.1.weight\", \"cnn.features.6.0.block.0.1.bias\", \"cnn.features.6.0.block.0.1.running_mean\", \"cnn.features.6.0.block.0.1.running_var\", \"cnn.features.6.0.block.0.1.num_batches_tracked\", \"cnn.features.6.0.block.1.0.weight\", \"cnn.features.6.0.block.1.1.weight\", \"cnn.features.6.0.block.1.1.bias\", \"cnn.features.6.0.block.1.1.running_mean\", \"cnn.features.6.0.block.1.1.running_var\", \"cnn.features.6.0.block.1.1.num_batches_tracked\", \"cnn.features.6.0.block.2.fc1.weight\", \"cnn.features.6.0.block.2.fc1.bias\", \"cnn.features.6.0.block.2.fc2.weight\", \"cnn.features.6.0.block.2.fc2.bias\", \"cnn.features.6.0.block.3.0.weight\", \"cnn.features.6.0.block.3.1.weight\", \"cnn.features.6.0.block.3.1.bias\", \"cnn.features.6.0.block.3.1.running_mean\", \"cnn.features.6.0.block.3.1.running_var\", \"cnn.features.6.0.block.3.1.num_batches_tracked\", \"cnn.features.6.1.block.0.0.weight\", \"cnn.features.6.1.block.0.1.weight\", \"cnn.features.6.1.block.0.1.bias\", \"cnn.features.6.1.block.0.1.running_mean\", \"cnn.features.6.1.block.0.1.running_var\", \"cnn.features.6.1.block.0.1.num_batches_tracked\", \"cnn.features.6.1.block.1.0.weight\", \"cnn.features.6.1.block.1.1.weight\", \"cnn.features.6.1.block.1.1.bias\", \"cnn.features.6.1.block.1.1.running_mean\", \"cnn.features.6.1.block.1.1.running_var\", \"cnn.features.6.1.block.1.1.num_batches_tracked\", \"cnn.features.6.1.block.2.fc1.weight\", \"cnn.features.6.1.block.2.fc1.bias\", \"cnn.features.6.1.block.2.fc2.weight\", \"cnn.features.6.1.block.2.fc2.bias\", \"cnn.features.6.1.block.3.0.weight\", \"cnn.features.6.1.block.3.1.weight\", \"cnn.features.6.1.block.3.1.bias\", \"cnn.features.6.1.block.3.1.running_mean\", \"cnn.features.6.1.block.3.1.running_var\", \"cnn.features.6.1.block.3.1.num_batches_tracked\", \"cnn.features.6.2.block.0.0.weight\", \"cnn.features.6.2.block.0.1.weight\", \"cnn.features.6.2.block.0.1.bias\", \"cnn.features.6.2.block.0.1.running_mean\", \"cnn.features.6.2.block.0.1.running_var\", \"cnn.features.6.2.block.0.1.num_batches_tracked\", \"cnn.features.6.2.block.1.0.weight\", \"cnn.features.6.2.block.1.1.weight\", \"cnn.features.6.2.block.1.1.bias\", \"cnn.features.6.2.block.1.1.running_mean\", \"cnn.features.6.2.block.1.1.running_var\", \"cnn.features.6.2.block.1.1.num_batches_tracked\", \"cnn.features.6.2.block.2.fc1.weight\", \"cnn.features.6.2.block.2.fc1.bias\", \"cnn.features.6.2.block.2.fc2.weight\", \"cnn.features.6.2.block.2.fc2.bias\", \"cnn.features.6.2.block.3.0.weight\", \"cnn.features.6.2.block.3.1.weight\", \"cnn.features.6.2.block.3.1.bias\", \"cnn.features.6.2.block.3.1.running_mean\", \"cnn.features.6.2.block.3.1.running_var\", \"cnn.features.6.2.block.3.1.num_batches_tracked\", \"cnn.features.6.3.block.0.0.weight\", \"cnn.features.6.3.block.0.1.weight\", \"cnn.features.6.3.block.0.1.bias\", \"cnn.features.6.3.block.0.1.running_mean\", \"cnn.features.6.3.block.0.1.running_var\", \"cnn.features.6.3.block.0.1.num_batches_tracked\", \"cnn.features.6.3.block.1.0.weight\", \"cnn.features.6.3.block.1.1.weight\", \"cnn.features.6.3.block.1.1.bias\", \"cnn.features.6.3.block.1.1.running_mean\", \"cnn.features.6.3.block.1.1.running_var\", \"cnn.features.6.3.block.1.1.num_batches_tracked\", \"cnn.features.6.3.block.2.fc1.weight\", \"cnn.features.6.3.block.2.fc1.bias\", \"cnn.features.6.3.block.2.fc2.weight\", \"cnn.features.6.3.block.2.fc2.bias\", \"cnn.features.6.3.block.3.0.weight\", \"cnn.features.6.3.block.3.1.weight\", \"cnn.features.6.3.block.3.1.bias\", \"cnn.features.6.3.block.3.1.running_mean\", \"cnn.features.6.3.block.3.1.running_var\", \"cnn.features.6.3.block.3.1.num_batches_tracked\", \"cnn.features.6.4.block.0.0.weight\", \"cnn.features.6.4.block.0.1.weight\", \"cnn.features.6.4.block.0.1.bias\", \"cnn.features.6.4.block.0.1.running_mean\", \"cnn.features.6.4.block.0.1.running_var\", \"cnn.features.6.4.block.0.1.num_batches_tracked\", \"cnn.features.6.4.block.1.0.weight\", \"cnn.features.6.4.block.1.1.weight\", \"cnn.features.6.4.block.1.1.bias\", \"cnn.features.6.4.block.1.1.running_mean\", \"cnn.features.6.4.block.1.1.running_var\", \"cnn.features.6.4.block.1.1.num_batches_tracked\", \"cnn.features.6.4.block.2.fc1.weight\", \"cnn.features.6.4.block.2.fc1.bias\", \"cnn.features.6.4.block.2.fc2.weight\", \"cnn.features.6.4.block.2.fc2.bias\", \"cnn.features.6.4.block.3.0.weight\", \"cnn.features.6.4.block.3.1.weight\", \"cnn.features.6.4.block.3.1.bias\", \"cnn.features.6.4.block.3.1.running_mean\", \"cnn.features.6.4.block.3.1.running_var\", \"cnn.features.6.4.block.3.1.num_batches_tracked\", \"cnn.features.7.0.block.0.0.weight\", \"cnn.features.7.0.block.0.1.weight\", \"cnn.features.7.0.block.0.1.bias\", \"cnn.features.7.0.block.0.1.running_mean\", \"cnn.features.7.0.block.0.1.running_var\", \"cnn.features.7.0.block.0.1.num_batches_tracked\", \"cnn.features.7.0.block.1.0.weight\", \"cnn.features.7.0.block.1.1.weight\", \"cnn.features.7.0.block.1.1.bias\", \"cnn.features.7.0.block.1.1.running_mean\", \"cnn.features.7.0.block.1.1.running_var\", \"cnn.features.7.0.block.1.1.num_batches_tracked\", \"cnn.features.7.0.block.2.fc1.weight\", \"cnn.features.7.0.block.2.fc1.bias\", \"cnn.features.7.0.block.2.fc2.weight\", \"cnn.features.7.0.block.2.fc2.bias\", \"cnn.features.7.0.block.3.0.weight\", \"cnn.features.7.0.block.3.1.weight\", \"cnn.features.7.0.block.3.1.bias\", \"cnn.features.7.0.block.3.1.running_mean\", \"cnn.features.7.0.block.3.1.running_var\", \"cnn.features.7.0.block.3.1.num_batches_tracked\", \"cnn.features.7.1.block.0.0.weight\", \"cnn.features.7.1.block.0.1.weight\", \"cnn.features.7.1.block.0.1.bias\", \"cnn.features.7.1.block.0.1.running_mean\", \"cnn.features.7.1.block.0.1.running_var\", \"cnn.features.7.1.block.0.1.num_batches_tracked\", \"cnn.features.7.1.block.1.0.weight\", \"cnn.features.7.1.block.1.1.weight\", \"cnn.features.7.1.block.1.1.bias\", \"cnn.features.7.1.block.1.1.running_mean\", \"cnn.features.7.1.block.1.1.running_var\", \"cnn.features.7.1.block.1.1.num_batches_tracked\", \"cnn.features.7.1.block.2.fc1.weight\", \"cnn.features.7.1.block.2.fc1.bias\", \"cnn.features.7.1.block.2.fc2.weight\", \"cnn.features.7.1.block.2.fc2.bias\", \"cnn.features.7.1.block.3.0.weight\", \"cnn.features.7.1.block.3.1.weight\", \"cnn.features.7.1.block.3.1.bias\", \"cnn.features.7.1.block.3.1.running_mean\", \"cnn.features.7.1.block.3.1.running_var\", \"cnn.features.7.1.block.3.1.num_batches_tracked\", \"cnn.features.8.0.weight\", \"cnn.features.8.1.weight\", \"cnn.features.8.1.bias\", \"cnn.features.8.1.running_mean\", \"cnn.features.8.1.running_var\", \"cnn.features.8.1.num_batches_tracked\", \"cnn.classifier.1.weight\", \"cnn.classifier.1.bias\". "
     ]
    }
   ],
   "source": [
    "if not config.USE_DENOISING_AUTOENCODER:\n",
    "    evaluate_model(config.CNN_ENCODER_SAVE_PATH, val_loader, device)\n",
    "else:\n",
    "    evaluate_model(config.CNN_ENCODER_SAVE_PATH, noisy_val_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
