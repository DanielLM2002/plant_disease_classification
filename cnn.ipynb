{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esteban Castañeda Blanco C01795\n",
    "Israel López Vallecillo C04396\n",
    "Daniel Lizano Morales C04285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'Plant_leave_diseases_dataset'\n",
    "classes = [\n",
    "  'Apple___Apple_scab',\n",
    "  'Apple___Black_rot',\n",
    "  'Apple___Cedar_apple_rust',\n",
    "  'Apple___healthy',\n",
    "  'Background_without_leaves',\n",
    "  'Blueberry___healthy',\n",
    "  'Cherry___healthy',\n",
    "  'Cherry___Powdery_mildew',\n",
    "  'Corn___Cercospora_leaf_spot Gray_leaf_spot',\n",
    "  'Corn___Common_rust',\n",
    "  'Corn___healthy',\n",
    "  'Corn___Northern_Leaf_Blight',\n",
    "  'Grape___Black_rot',\n",
    "  'Grape___Esca_(Black_Measles)',\n",
    "  'Grape___healthy',\n",
    "  'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
    "  'Orange___Haunglongbing_(Citrus_greening)',\n",
    "  'Peach___Bacterial_spot',\n",
    "  'Peach___healthy',\n",
    "  'Pepper,_bell___Bacterial_spot',\n",
    "  'Pepper,_bell___healthy',\n",
    "  'Potato___Early_blight',\n",
    "  'Potato___healthy',\n",
    "  'Potato___Late_blight',\n",
    "  'Raspberry___healthy',\n",
    "  'Soybean___healthy',\n",
    "  'Squash___Powdery_mildew',\n",
    "  'Strawberry___healthy',\n",
    "  'Strawberry___Leaf_scorch',\n",
    "  'Tomato___Bacterial_spot',\n",
    "  'Tomato___Early_blight',\n",
    "  'Tomato___healthy',\n",
    "  'Tomato___Late_blight',\n",
    "  'Tomato___Leaf_Mold',\n",
    "  'Tomato___Septoria_leaf_spot',\n",
    "  'Tomato___Spider_mites Two-spotted_spider_mite',\n",
    "  'Tomato___Target_Spot',\n",
    "  'Tomato___Tomato_mosaic_virus',\n",
    "  'Tomato___Tomato_Yellow_Leaf_Curl_Virus'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "  'train': transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]) \n",
    "  ]),\n",
    "  'val': transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "  ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir_original = os.path.join(base_dir, 'train')\n",
    "val_dir_original = os.path.join(base_dir, 'val')\n",
    "os.makedirs(train_dir_original, exist_ok=True)\n",
    "os.makedirs(val_dir_original, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.listdir(train_dir_original) or not os.listdir(val_dir_original):\n",
    "  # Copy data to the correct directories if not already done\n",
    "  for category in classes:\n",
    "    category_path = os.path.join(base_dir, 'original', category)\n",
    "    images = os.listdir(category_path)\n",
    "\n",
    "    # Ensure the category directories exist in train and val directories\n",
    "    train_category_dir = os.path.join(train_dir_original, category)\n",
    "    val_category_dir = os.path.join(val_dir_original, category)\n",
    "    os.makedirs(train_category_dir, exist_ok=True)\n",
    "    os.makedirs(val_category_dir, exist_ok=True)\n",
    "    train_images = images[:int(len(images) * 0.8)]\n",
    "    val_images = images[int(len(images) * 0.8):]\n",
    "    for img in tqdm(train_images, desc=f\"Copying train images for {category}\"):\n",
    "      src_path = os.path.join(category_path, img)\n",
    "      dst_path = os.path.join(train_category_dir, img)\n",
    "      if not os.path.exists(dst_path):\n",
    "        shutil.copy(src_path, dst_path)\n",
    "    for img in tqdm(val_images, desc=f\"Copying val images for {category}\"):\n",
    "      src_path = os.path.join(category_path, img)\n",
    "      dst_path = os.path.join(val_category_dir, img)\n",
    "      if not os.path.exists(dst_path):\n",
    "        shutil.copy(src_path, dst_path)\n",
    "\n",
    "print(\"\\nTrain Directory Structure:\")\n",
    "for root, dirs, files in os.walk(train_dir_original):\n",
    "  print(root, \"contains\", len(files), \"files\")\n",
    "\n",
    "print(\"\\nValidation Directory Structure:\")\n",
    "for root, dirs, files in os.walk(val_dir_original):\n",
    "  print(root, \"contains\", len(files), \"files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_original = datasets.ImageFolder(train_dir_original, transform=data_transforms['train'])\n",
    "val_dataset_original = datasets.ImageFolder(val_dir_original, transform=data_transforms['val'])\n",
    "train_loader_original = DataLoader(train_dataset_original, batch_size=32, shuffle=True)\n",
    "val_loader_original = DataLoader(val_dataset_original, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_original = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "num_classes_original = len(train_dataset_original.classes)\n",
    "model_original._conv_stem = nn.Conv2d(1, model_original._conv_stem.out_channels, \n",
    "                             kernel_size=model_original._conv_stem.kernel_size, \n",
    "                             stride=model_original._conv_stem.stride, \n",
    "                             padding=model_original._conv_stem.padding, \n",
    "                             bias=False)\n",
    "model_original._fc = nn.Linear(model_original._fc.in_features, num_classes_original)\n",
    "model_original = model_original.to(device)\n",
    "criterion_original = nn.CrossEntropyLoss()\n",
    "optimizer_original = torch.optim.Adam(model_original.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, device, num_epochs=50, patience=5):\n",
    "  best_val_loss = float('inf')\n",
    "  epochs_no_improve = 0\n",
    "  model_save_path = '.pth'\n",
    "  os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "  for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    #Training phase with progress bar\n",
    "    train_progress = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\", unit=\"batch\")\n",
    "    for inputs, labels in train_progress:\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item() * inputs.size(0)\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "      train_progress.set_postfix({\"Loss\": running_loss / total, \"Acc\": correct / total})\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        val_total += labels.size(0)\n",
    "        val_correct += (predicted == labels).sum().item()\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    val_acc = val_correct / val_total\n",
    "    print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "\n",
    "    #Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "      best_val_loss = val_loss\n",
    "      epochs_no_improve = 0\n",
    "      torch.save(model.state_dict(), model_save_path)  # Save the best model\n",
    "    else:\n",
    "      epochs_no_improve += 1\n",
    "    if epochs_no_improve >= patience:\n",
    "      print(\"Early stopping triggered!\")\n",
    "      break\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "  figure = plt.figure(figsize=(8, 8))\n",
    "  sns.heatmap(cm, annot=True, cmap=plt.cm.Blues, fmt='g', xticklabels=class_names, yticklabels=class_names)\n",
    "  plt.xlabel('Predicted label')\n",
    "  plt.ylabel('True label')\n",
    "  plt.title('Confusion Matrix')\n",
    "  return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  all_preds = []\n",
    "  all_labels = []\n",
    "  with torch.no_grad():\n",
    "    for inputs, labels in dataloader:\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "      outputs = model(inputs)\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "\n",
    "      all_preds.extend(predicted.cpu().numpy())\n",
    "      all_labels.extend(labels.cpu().numpy())\n",
    "  accuracy = correct / total\n",
    "  cm = confusion_matrix(all_labels, all_preds)\n",
    "  cm_figure = plot_confusion_matrix(cm, class_names=dataloader.dataset.classes)\n",
    "\n",
    "  # Print and show the confusion matrix\n",
    "  plt.figure(figsize=(8, 8))\n",
    "  sns.heatmap(cm, annot=True, cmap=plt.cm.Blues, fmt='g', xticklabels=dataloader.dataset.classes, yticklabels=dataloader.dataset.classes)\n",
    "  plt.xlabel('Predicted label')\n",
    "  plt.ylabel('True label')\n",
    "  plt.title('Confusion Matrix - Evaluation')\n",
    "  plt.show()\n",
    "  print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_original = train_model(model_original, criterion_original, optimizer_original, train_loader_original, val_loader_original, device, num_epochs=10, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(trained_model_original, val_loader_original, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
